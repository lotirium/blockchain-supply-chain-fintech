import {
  code as code3,
  code2 as code4,
  code3 as code5,
  decode as decode3,
  decode3 as decode4,
  decode4 as decode5,
  encode,
  prepare,
  src_default,
  src_default2 as src_default4,
  src_exports
} from "./chunk-BMUNWA4X.js";
import {
  PQueue,
  logger,
  merge_options_default,
  parallel,
  require_murmurhash3js_revisited,
  src_default as src_default2,
  src_default2 as src_default3
} from "./chunk-QWUFDZHL.js";
import {
  CustomProgressEvent
} from "./chunk-2LXZBJZU.js";
import {
  pipe
} from "./chunk-U3CLON27.js";
import "./chunk-TDJ2YZLS.js";
import {
  decodeMessage,
  encodeMessage,
  enumeration,
  message
} from "./chunk-5HCC54LS.js";
import "./chunk-QINVXJCG.js";
import {
  fromString
} from "./chunk-AKRWU5PV.js";
import {
  code,
  code2,
  decode as decode2,
  from,
  identity,
  raw_exports,
  sha256
} from "./chunk-LJV7FKKR.js";
import {
  CID,
  bytes_exports,
  decode
} from "./chunk-LLHUIDBD.js";
import {
  Uint8ArrayList,
  pushable
} from "./chunk-L26C3OVL.js";
import "./chunk-GYD5GS2D.js";
import {
  concat
} from "./chunk-SVJZTA62.js";
import "./chunk-UVKKAIIP.js";
import {
  __commonJS,
  __publicField,
  __toESM
} from "./chunk-QY3AG7D4.js";

// node_modules/sparse-array/index.js
var require_sparse_array = __commonJS({
  "node_modules/sparse-array/index.js"(exports, module) {
    "use strict";
    var BITS_PER_BYTE = 7;
    module.exports = class SparseArray {
      constructor() {
        this._bitArrays = [];
        this._data = [];
        this._length = 0;
        this._changedLength = false;
        this._changedData = false;
      }
      set(index, value) {
        let pos = this._internalPositionFor(index, false);
        if (value === void 0) {
          if (pos !== -1) {
            this._unsetInternalPos(pos);
            this._unsetBit(index);
            this._changedLength = true;
            this._changedData = true;
          }
        } else {
          let needsSort = false;
          if (pos === -1) {
            pos = this._data.length;
            this._setBit(index);
            this._changedData = true;
          } else {
            needsSort = true;
          }
          this._setInternalPos(pos, index, value, needsSort);
          this._changedLength = true;
        }
      }
      unset(index) {
        this.set(index, void 0);
      }
      get(index) {
        this._sortData();
        const pos = this._internalPositionFor(index, true);
        if (pos === -1) {
          return void 0;
        }
        return this._data[pos][1];
      }
      push(value) {
        this.set(this.length, value);
        return this.length;
      }
      get length() {
        this._sortData();
        if (this._changedLength) {
          const last2 = this._data[this._data.length - 1];
          this._length = last2 ? last2[0] + 1 : 0;
          this._changedLength = false;
        }
        return this._length;
      }
      forEach(iterator) {
        let i = 0;
        while (i < this.length) {
          iterator(this.get(i), i, this);
          i++;
        }
      }
      map(iterator) {
        let i = 0;
        let mapped = new Array(this.length);
        while (i < this.length) {
          mapped[i] = iterator(this.get(i), i, this);
          i++;
        }
        return mapped;
      }
      reduce(reducer, initialValue) {
        let i = 0;
        let acc = initialValue;
        while (i < this.length) {
          const value = this.get(i);
          acc = reducer(acc, value, i);
          i++;
        }
        return acc;
      }
      find(finder) {
        let i = 0, found, last2;
        while (i < this.length && !found) {
          last2 = this.get(i);
          found = finder(last2);
          i++;
        }
        return found ? last2 : void 0;
      }
      _internalPositionFor(index, noCreate) {
        const bytePos = this._bytePosFor(index, noCreate);
        if (bytePos >= this._bitArrays.length) {
          return -1;
        }
        const byte = this._bitArrays[bytePos];
        const bitPos = index - bytePos * BITS_PER_BYTE;
        const exists2 = (byte & 1 << bitPos) > 0;
        if (!exists2) {
          return -1;
        }
        const previousPopCount = this._bitArrays.slice(0, bytePos).reduce(popCountReduce, 0);
        const mask = ~(4294967295 << bitPos + 1);
        const bytePopCount = popCount(byte & mask);
        const arrayPos = previousPopCount + bytePopCount - 1;
        return arrayPos;
      }
      _bytePosFor(index, noCreate) {
        const bytePos = Math.floor(index / BITS_PER_BYTE);
        const targetLength = bytePos + 1;
        while (!noCreate && this._bitArrays.length < targetLength) {
          this._bitArrays.push(0);
        }
        return bytePos;
      }
      _setBit(index) {
        const bytePos = this._bytePosFor(index, false);
        this._bitArrays[bytePos] |= 1 << index - bytePos * BITS_PER_BYTE;
      }
      _unsetBit(index) {
        const bytePos = this._bytePosFor(index, false);
        this._bitArrays[bytePos] &= ~(1 << index - bytePos * BITS_PER_BYTE);
      }
      _setInternalPos(pos, index, value, needsSort) {
        const data = this._data;
        const elem = [index, value];
        if (needsSort) {
          this._sortData();
          data[pos] = elem;
        } else {
          if (data.length) {
            if (data[data.length - 1][0] >= index) {
              data.push(elem);
            } else if (data[0][0] <= index) {
              data.unshift(elem);
            } else {
              const randomIndex = Math.round(data.length / 2);
              this._data = data.slice(0, randomIndex).concat(elem).concat(data.slice(randomIndex));
            }
          } else {
            this._data.push(elem);
          }
          this._changedData = true;
          this._changedLength = true;
        }
      }
      _unsetInternalPos(pos) {
        this._data.splice(pos, 1);
      }
      _sortData() {
        if (this._changedData) {
          this._data.sort(sortInternal);
        }
        this._changedData = false;
      }
      bitField() {
        const bytes = [];
        let pendingBitsForResultingByte = 8;
        let pendingBitsForNewByte = 0;
        let resultingByte = 0;
        let newByte;
        const pending = this._bitArrays.slice();
        while (pending.length || pendingBitsForNewByte) {
          if (pendingBitsForNewByte === 0) {
            newByte = pending.shift();
            pendingBitsForNewByte = 7;
          }
          const usingBits = Math.min(pendingBitsForNewByte, pendingBitsForResultingByte);
          const mask = ~(255 << usingBits);
          const masked = newByte & mask;
          resultingByte |= masked << 8 - pendingBitsForResultingByte;
          newByte = newByte >>> usingBits;
          pendingBitsForNewByte -= usingBits;
          pendingBitsForResultingByte -= usingBits;
          if (!pendingBitsForResultingByte || !pendingBitsForNewByte && !pending.length) {
            bytes.push(resultingByte);
            resultingByte = 0;
            pendingBitsForResultingByte = 8;
          }
        }
        for (var i = bytes.length - 1; i > 0; i--) {
          const value = bytes[i];
          if (value === 0) {
            bytes.pop();
          } else {
            break;
          }
        }
        return bytes;
      }
      compactArray() {
        this._sortData();
        return this._data.map(valueOnly);
      }
    };
    function popCountReduce(count, byte) {
      return count + popCount(byte);
    }
    function popCount(_v) {
      let v = _v;
      v = v - (v >> 1 & 1431655765);
      v = (v & 858993459) + (v >> 2 & 858993459);
      return (v + (v >> 4) & 252645135) * 16843009 >> 24;
    }
    function sortInternal(a, b) {
      return a[0] - b[0];
    }
    function valueOnly(elem) {
      return elem[1];
    }
  }
});

// node_modules/rabin-wasm/src/rabin.js
var require_rabin = __commonJS({
  "node_modules/rabin-wasm/src/rabin.js"(exports, module) {
    var Rabin = class {
      /**
       * Creates an instance of Rabin.
       * @param { import("./../dist/rabin-wasm") } asModule
       * @param {number} [bits=12]
       * @param {number} [min=8 * 1024]
       * @param {number} [max=32 * 1024]
       * @param {number} polynomial
       * @memberof Rabin
       */
      constructor(asModule, bits = 12, min = 8 * 1024, max = 32 * 1024, windowSize = 64, polynomial) {
        this.bits = bits;
        this.min = min;
        this.max = max;
        this.asModule = asModule;
        this.rabin = new asModule.Rabin(bits, min, max, windowSize, polynomial);
        this.polynomial = polynomial;
      }
      /**
       * Fingerprints the buffer
       *
       * @param {Uint8Array} buf
       * @returns {Array<number>}
       * @memberof Rabin
       */
      fingerprint(buf) {
        const {
          __retain,
          __release,
          __allocArray,
          __getInt32Array,
          Int32Array_ID,
          Uint8Array_ID
        } = this.asModule;
        const lengths = new Int32Array(Math.ceil(buf.length / this.min));
        const lengthsPtr = __retain(__allocArray(Int32Array_ID, lengths));
        const pointer = __retain(__allocArray(Uint8Array_ID, buf));
        const out = this.rabin.fingerprint(pointer, lengthsPtr);
        const processed = __getInt32Array(out);
        __release(pointer);
        __release(lengthsPtr);
        const end = processed.indexOf(0);
        return end >= 0 ? processed.subarray(0, end) : processed;
      }
    };
    module.exports = Rabin;
  }
});

// node_modules/@assemblyscript/loader/index.js
var require_loader = __commonJS({
  "node_modules/@assemblyscript/loader/index.js"(exports) {
    "use strict";
    var ID_OFFSET = -8;
    var SIZE_OFFSET = -4;
    var ARRAYBUFFER_ID = 0;
    var STRING_ID = 1;
    var ARRAYBUFFERVIEW = 1 << 0;
    var ARRAY = 1 << 1;
    var SET = 1 << 2;
    var MAP = 1 << 3;
    var VAL_ALIGN_OFFSET = 5;
    var VAL_ALIGN = 1 << VAL_ALIGN_OFFSET;
    var VAL_SIGNED = 1 << 10;
    var VAL_FLOAT = 1 << 11;
    var VAL_NULLABLE = 1 << 12;
    var VAL_MANAGED = 1 << 13;
    var KEY_ALIGN_OFFSET = 14;
    var KEY_ALIGN = 1 << KEY_ALIGN_OFFSET;
    var KEY_SIGNED = 1 << 19;
    var KEY_FLOAT = 1 << 20;
    var KEY_NULLABLE = 1 << 21;
    var KEY_MANAGED = 1 << 22;
    var ARRAYBUFFERVIEW_BUFFER_OFFSET = 0;
    var ARRAYBUFFERVIEW_DATASTART_OFFSET = 4;
    var ARRAYBUFFERVIEW_DATALENGTH_OFFSET = 8;
    var ARRAYBUFFERVIEW_SIZE = 12;
    var ARRAY_LENGTH_OFFSET = 12;
    var ARRAY_SIZE = 16;
    var BIGINT = typeof BigUint64Array !== "undefined";
    var THIS = Symbol();
    var CHUNKSIZE = 1024;
    function getStringImpl(buffer, ptr) {
      const U32 = new Uint32Array(buffer);
      const U16 = new Uint16Array(buffer);
      var length = U32[ptr + SIZE_OFFSET >>> 2] >>> 1;
      var offset = ptr >>> 1;
      if (length <= CHUNKSIZE)
        return String.fromCharCode.apply(String, U16.subarray(offset, offset + length));
      const parts = [];
      do {
        const last2 = U16[offset + CHUNKSIZE - 1];
        const size = last2 >= 55296 && last2 < 56320 ? CHUNKSIZE - 1 : CHUNKSIZE;
        parts.push(String.fromCharCode.apply(String, U16.subarray(offset, offset += size)));
        length -= size;
      } while (length > CHUNKSIZE);
      return parts.join("") + String.fromCharCode.apply(String, U16.subarray(offset, offset + length));
    }
    function preInstantiate(imports) {
      const baseModule = {};
      function getString(memory, ptr) {
        if (!memory)
          return "<yet unknown>";
        return getStringImpl(memory.buffer, ptr);
      }
      const env = imports.env = imports.env || {};
      env.abort = env.abort || function abort(mesg, file, line, colm) {
        const memory = baseModule.memory || env.memory;
        throw Error("abort: " + getString(memory, mesg) + " at " + getString(memory, file) + ":" + line + ":" + colm);
      };
      env.trace = env.trace || function trace(mesg, n) {
        const memory = baseModule.memory || env.memory;
        console.log("trace: " + getString(memory, mesg) + (n ? " " : "") + Array.prototype.slice.call(arguments, 2, 2 + n).join(", "));
      };
      imports.Math = imports.Math || Math;
      imports.Date = imports.Date || Date;
      return baseModule;
    }
    function postInstantiate(baseModule, instance) {
      const rawExports = instance.exports;
      const memory = rawExports.memory;
      const table = rawExports.table;
      const alloc = rawExports["__alloc"];
      const retain = rawExports["__retain"];
      const rttiBase = rawExports["__rtti_base"] || ~0;
      function getInfo(id) {
        const U32 = new Uint32Array(memory.buffer);
        const count = U32[rttiBase >>> 2];
        if ((id >>>= 0) >= count)
          throw Error("invalid id: " + id);
        return U32[(rttiBase + 4 >>> 2) + id * 2];
      }
      function getBase(id) {
        const U32 = new Uint32Array(memory.buffer);
        const count = U32[rttiBase >>> 2];
        if ((id >>>= 0) >= count)
          throw Error("invalid id: " + id);
        return U32[(rttiBase + 4 >>> 2) + id * 2 + 1];
      }
      function getValueAlign(info) {
        return 31 - Math.clz32(info >>> VAL_ALIGN_OFFSET & 31);
      }
      function getKeyAlign(info) {
        return 31 - Math.clz32(info >>> KEY_ALIGN_OFFSET & 31);
      }
      function __allocString(str) {
        const length = str.length;
        const ptr = alloc(length << 1, STRING_ID);
        const U16 = new Uint16Array(memory.buffer);
        for (var i = 0, p = ptr >>> 1; i < length; ++i)
          U16[p + i] = str.charCodeAt(i);
        return ptr;
      }
      baseModule.__allocString = __allocString;
      function __getString(ptr) {
        const buffer = memory.buffer;
        const id = new Uint32Array(buffer)[ptr + ID_OFFSET >>> 2];
        if (id !== STRING_ID)
          throw Error("not a string: " + ptr);
        return getStringImpl(buffer, ptr);
      }
      baseModule.__getString = __getString;
      function getView(alignLog2, signed, float) {
        const buffer = memory.buffer;
        if (float) {
          switch (alignLog2) {
            case 2:
              return new Float32Array(buffer);
            case 3:
              return new Float64Array(buffer);
          }
        } else {
          switch (alignLog2) {
            case 0:
              return new (signed ? Int8Array : Uint8Array)(buffer);
            case 1:
              return new (signed ? Int16Array : Uint16Array)(buffer);
            case 2:
              return new (signed ? Int32Array : Uint32Array)(buffer);
            case 3:
              return new (signed ? BigInt64Array : BigUint64Array)(buffer);
          }
        }
        throw Error("unsupported align: " + alignLog2);
      }
      function __allocArray(id, values) {
        const info = getInfo(id);
        if (!(info & (ARRAYBUFFERVIEW | ARRAY)))
          throw Error("not an array: " + id + " @ " + info);
        const align = getValueAlign(info);
        const length = values.length;
        const buf = alloc(length << align, ARRAYBUFFER_ID);
        const arr = alloc(info & ARRAY ? ARRAY_SIZE : ARRAYBUFFERVIEW_SIZE, id);
        const U32 = new Uint32Array(memory.buffer);
        U32[arr + ARRAYBUFFERVIEW_BUFFER_OFFSET >>> 2] = retain(buf);
        U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2] = buf;
        U32[arr + ARRAYBUFFERVIEW_DATALENGTH_OFFSET >>> 2] = length << align;
        if (info & ARRAY)
          U32[arr + ARRAY_LENGTH_OFFSET >>> 2] = length;
        const view = getView(align, info & VAL_SIGNED, info & VAL_FLOAT);
        if (info & VAL_MANAGED) {
          for (let i = 0; i < length; ++i)
            view[(buf >>> align) + i] = retain(values[i]);
        } else {
          view.set(values, buf >>> align);
        }
        return arr;
      }
      baseModule.__allocArray = __allocArray;
      function __getArrayView(arr) {
        const U32 = new Uint32Array(memory.buffer);
        const id = U32[arr + ID_OFFSET >>> 2];
        const info = getInfo(id);
        if (!(info & ARRAYBUFFERVIEW))
          throw Error("not an array: " + id);
        const align = getValueAlign(info);
        var buf = U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];
        const length = info & ARRAY ? U32[arr + ARRAY_LENGTH_OFFSET >>> 2] : U32[buf + SIZE_OFFSET >>> 2] >>> align;
        return getView(align, info & VAL_SIGNED, info & VAL_FLOAT).subarray(buf >>>= align, buf + length);
      }
      baseModule.__getArrayView = __getArrayView;
      function __getArray(arr) {
        const input = __getArrayView(arr);
        const len = input.length;
        const out = new Array(len);
        for (let i = 0; i < len; i++)
          out[i] = input[i];
        return out;
      }
      baseModule.__getArray = __getArray;
      function __getArrayBuffer(ptr) {
        const buffer = memory.buffer;
        const length = new Uint32Array(buffer)[ptr + SIZE_OFFSET >>> 2];
        return buffer.slice(ptr, ptr + length);
      }
      baseModule.__getArrayBuffer = __getArrayBuffer;
      function getTypedArray(Type, alignLog2, ptr) {
        return new Type(getTypedArrayView(Type, alignLog2, ptr));
      }
      function getTypedArrayView(Type, alignLog2, ptr) {
        const buffer = memory.buffer;
        const U32 = new Uint32Array(buffer);
        const bufPtr = U32[ptr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];
        return new Type(buffer, bufPtr, U32[bufPtr + SIZE_OFFSET >>> 2] >>> alignLog2);
      }
      baseModule.__getInt8Array = getTypedArray.bind(null, Int8Array, 0);
      baseModule.__getInt8ArrayView = getTypedArrayView.bind(null, Int8Array, 0);
      baseModule.__getUint8Array = getTypedArray.bind(null, Uint8Array, 0);
      baseModule.__getUint8ArrayView = getTypedArrayView.bind(null, Uint8Array, 0);
      baseModule.__getUint8ClampedArray = getTypedArray.bind(null, Uint8ClampedArray, 0);
      baseModule.__getUint8ClampedArrayView = getTypedArrayView.bind(null, Uint8ClampedArray, 0);
      baseModule.__getInt16Array = getTypedArray.bind(null, Int16Array, 1);
      baseModule.__getInt16ArrayView = getTypedArrayView.bind(null, Int16Array, 1);
      baseModule.__getUint16Array = getTypedArray.bind(null, Uint16Array, 1);
      baseModule.__getUint16ArrayView = getTypedArrayView.bind(null, Uint16Array, 1);
      baseModule.__getInt32Array = getTypedArray.bind(null, Int32Array, 2);
      baseModule.__getInt32ArrayView = getTypedArrayView.bind(null, Int32Array, 2);
      baseModule.__getUint32Array = getTypedArray.bind(null, Uint32Array, 2);
      baseModule.__getUint32ArrayView = getTypedArrayView.bind(null, Uint32Array, 2);
      if (BIGINT) {
        baseModule.__getInt64Array = getTypedArray.bind(null, BigInt64Array, 3);
        baseModule.__getInt64ArrayView = getTypedArrayView.bind(null, BigInt64Array, 3);
        baseModule.__getUint64Array = getTypedArray.bind(null, BigUint64Array, 3);
        baseModule.__getUint64ArrayView = getTypedArrayView.bind(null, BigUint64Array, 3);
      }
      baseModule.__getFloat32Array = getTypedArray.bind(null, Float32Array, 2);
      baseModule.__getFloat32ArrayView = getTypedArrayView.bind(null, Float32Array, 2);
      baseModule.__getFloat64Array = getTypedArray.bind(null, Float64Array, 3);
      baseModule.__getFloat64ArrayView = getTypedArrayView.bind(null, Float64Array, 3);
      function __instanceof(ptr, baseId) {
        const U32 = new Uint32Array(memory.buffer);
        var id = U32[ptr + ID_OFFSET >>> 2];
        if (id <= U32[rttiBase >>> 2]) {
          do
            if (id == baseId)
              return true;
          while (id = getBase(id));
        }
        return false;
      }
      baseModule.__instanceof = __instanceof;
      baseModule.memory = baseModule.memory || memory;
      baseModule.table = baseModule.table || table;
      return demangle(rawExports, baseModule);
    }
    function isResponse(o) {
      return typeof Response !== "undefined" && o instanceof Response;
    }
    async function instantiate(source, imports) {
      if (isResponse(source = await source))
        return instantiateStreaming(source, imports);
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        await WebAssembly.instantiate(
          source instanceof WebAssembly.Module ? source : await WebAssembly.compile(source),
          imports
        )
      );
    }
    exports.instantiate = instantiate;
    function instantiateSync(source, imports) {
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        new WebAssembly.Instance(
          source instanceof WebAssembly.Module ? source : new WebAssembly.Module(source),
          imports
        )
      );
    }
    exports.instantiateSync = instantiateSync;
    async function instantiateStreaming(source, imports) {
      if (!WebAssembly.instantiateStreaming) {
        return instantiate(
          isResponse(source = await source) ? source.arrayBuffer() : source,
          imports
        );
      }
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        (await WebAssembly.instantiateStreaming(source, imports)).instance
      );
    }
    exports.instantiateStreaming = instantiateStreaming;
    function demangle(exports2, baseModule) {
      var module2 = baseModule ? Object.create(baseModule) : {};
      var setArgumentsLength = exports2["__argumentsLength"] ? function(length) {
        exports2["__argumentsLength"].value = length;
      } : exports2["__setArgumentsLength"] || exports2["__setargc"] || function() {
      };
      for (let internalName in exports2) {
        if (!Object.prototype.hasOwnProperty.call(exports2, internalName))
          continue;
        const elem = exports2[internalName];
        let parts = internalName.split(".");
        let curr = module2;
        while (parts.length > 1) {
          let part = parts.shift();
          if (!Object.prototype.hasOwnProperty.call(curr, part))
            curr[part] = {};
          curr = curr[part];
        }
        let name = parts[0];
        let hash = name.indexOf("#");
        if (hash >= 0) {
          let className = name.substring(0, hash);
          let classElem = curr[className];
          if (typeof classElem === "undefined" || !classElem.prototype) {
            let ctor = function(...args) {
              return ctor.wrap(ctor.prototype.constructor(0, ...args));
            };
            ctor.prototype = {
              valueOf: function valueOf() {
                return this[THIS];
              }
            };
            ctor.wrap = function(thisValue) {
              return Object.create(ctor.prototype, { [THIS]: { value: thisValue, writable: false } });
            };
            if (classElem)
              Object.getOwnPropertyNames(classElem).forEach(
                (name2) => Object.defineProperty(ctor, name2, Object.getOwnPropertyDescriptor(classElem, name2))
              );
            curr[className] = ctor;
          }
          name = name.substring(hash + 1);
          curr = curr[className].prototype;
          if (/^(get|set):/.test(name)) {
            if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {
              let getter = exports2[internalName.replace("set:", "get:")];
              let setter = exports2[internalName.replace("get:", "set:")];
              Object.defineProperty(curr, name, {
                get: function() {
                  return getter(this[THIS]);
                },
                set: function(value) {
                  setter(this[THIS], value);
                },
                enumerable: true
              });
            }
          } else {
            if (name === "constructor") {
              (curr[name] = (...args) => {
                setArgumentsLength(args.length);
                return elem(...args);
              }).original = elem;
            } else {
              (curr[name] = function(...args) {
                setArgumentsLength(args.length);
                return elem(this[THIS], ...args);
              }).original = elem;
            }
          }
        } else {
          if (/^(get|set):/.test(name)) {
            if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {
              Object.defineProperty(curr, name, {
                get: exports2[internalName.replace("set:", "get:")],
                set: exports2[internalName.replace("get:", "set:")],
                enumerable: true
              });
            }
          } else if (typeof elem === "function" && elem !== setArgumentsLength) {
            (curr[name] = (...args) => {
              setArgumentsLength(args.length);
              return elem(...args);
            }).original = elem;
          } else {
            curr[name] = elem;
          }
        }
      }
      return module2;
    }
    exports.demangle = demangle;
  }
});

// node_modules/rabin-wasm/dist/rabin-wasm.js
var require_rabin_wasm = __commonJS({
  "node_modules/rabin-wasm/dist/rabin-wasm.js"(exports, module) {
    var { instantiate } = require_loader();
    loadWebAssembly.supported = typeof WebAssembly !== "undefined";
    function loadWebAssembly(imp = {}) {
      if (!loadWebAssembly.supported)
        return null;
      var wasm = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 78, 14, 96, 2, 127, 126, 0, 96, 1, 127, 1, 126, 96, 2, 127, 127, 0, 96, 1, 127, 1, 127, 96, 1, 127, 0, 96, 2, 127, 127, 1, 127, 96, 3, 127, 127, 127, 1, 127, 96, 0, 0, 96, 3, 127, 127, 127, 0, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 0, 96, 5, 127, 127, 127, 127, 127, 1, 127, 96, 1, 126, 1, 127, 96, 2, 126, 126, 1, 126, 2, 13, 1, 3, 101, 110, 118, 5, 97, 98, 111, 114, 116, 0, 10, 3, 54, 53, 2, 2, 8, 9, 3, 5, 2, 8, 6, 5, 3, 4, 2, 6, 9, 12, 13, 2, 5, 11, 3, 2, 3, 2, 3, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 6, 7, 7, 4, 4, 5, 3, 1, 0, 1, 6, 47, 9, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 0, 65, 3, 11, 127, 0, 65, 4, 11, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 0, 65, 240, 2, 11, 127, 0, 65, 6, 11, 7, 240, 5, 41, 6, 109, 101, 109, 111, 114, 121, 2, 0, 7, 95, 95, 97, 108, 108, 111, 99, 0, 10, 8, 95, 95, 114, 101, 116, 97, 105, 110, 0, 11, 9, 95, 95, 114, 101, 108, 101, 97, 115, 101, 0, 12, 9, 95, 95, 99, 111, 108, 108, 101, 99, 116, 0, 51, 11, 95, 95, 114, 116, 116, 105, 95, 98, 97, 115, 101, 3, 7, 13, 73, 110, 116, 51, 50, 65, 114, 114, 97, 121, 95, 73, 68, 3, 2, 13, 85, 105, 110, 116, 56, 65, 114, 114, 97, 121, 95, 73, 68, 3, 3, 6, 100, 101, 103, 114, 101, 101, 0, 16, 3, 109, 111, 100, 0, 17, 5, 82, 97, 98, 105, 110, 3, 8, 16, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 105, 110, 100, 111, 119, 0, 21, 16, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 105, 110, 100, 111, 119, 0, 22, 21, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 105, 110, 100, 111, 119, 95, 115, 105, 122, 101, 0, 23, 21, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 105, 110, 100, 111, 119, 95, 115, 105, 122, 101, 0, 24, 14, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 112, 111, 115, 0, 25, 14, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 112, 111, 115, 0, 26, 15, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 111, 117, 110, 116, 0, 27, 15, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 111, 117, 110, 116, 0, 28, 13, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 112, 111, 115, 0, 29, 13, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 112, 111, 115, 0, 30, 15, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 115, 116, 97, 114, 116, 0, 31, 15, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 115, 116, 97, 114, 116, 0, 32, 16, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 100, 105, 103, 101, 115, 116, 0, 33, 16, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 100, 105, 103, 101, 115, 116, 0, 34, 21, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 115, 116, 97, 114, 116, 0, 35, 21, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 115, 116, 97, 114, 116, 0, 36, 22, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 108, 101, 110, 103, 116, 104, 0, 37, 22, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 108, 101, 110, 103, 116, 104, 0, 38, 31, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 99, 117, 116, 95, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 39, 31, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 99, 117, 116, 95, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 40, 20, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 112, 111, 108, 121, 110, 111, 109, 105, 97, 108, 0, 41, 20, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 112, 111, 108, 121, 110, 111, 109, 105, 97, 108, 0, 42, 17, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 105, 110, 115, 105, 122, 101, 0, 43, 17, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 105, 110, 115, 105, 122, 101, 0, 44, 17, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 97, 120, 115, 105, 122, 101, 0, 45, 17, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 97, 120, 115, 105, 122, 101, 0, 46, 14, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 97, 115, 107, 0, 47, 14, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 97, 115, 107, 0, 48, 17, 82, 97, 98, 105, 110, 35, 99, 111, 110, 115, 116, 114, 117, 99, 116, 111, 114, 0, 20, 17, 82, 97, 98, 105, 110, 35, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 49, 8, 1, 50, 10, 165, 31, 53, 199, 1, 1, 4, 127, 32, 1, 40, 2, 0, 65, 124, 113, 34, 2, 65, 128, 2, 73, 4, 127, 32, 2, 65, 4, 118, 33, 4, 65, 0, 5, 32, 2, 65, 31, 32, 2, 103, 107, 34, 3, 65, 4, 107, 118, 65, 16, 115, 33, 4, 32, 3, 65, 7, 107, 11, 33, 3, 32, 1, 40, 2, 20, 33, 2, 32, 1, 40, 2, 16, 34, 5, 4, 64, 32, 5, 32, 2, 54, 2, 20, 11, 32, 2, 4, 64, 32, 2, 32, 5, 54, 2, 16, 11, 32, 1, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 70, 4, 64, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 32, 2, 54, 2, 96, 32, 2, 69, 4, 64, 32, 0, 32, 3, 65, 2, 116, 106, 32, 0, 32, 3, 65, 2, 116, 106, 40, 2, 4, 65, 1, 32, 4, 116, 65, 127, 115, 113, 34, 1, 54, 2, 4, 32, 1, 69, 4, 64, 32, 0, 32, 0, 40, 2, 0, 65, 1, 32, 3, 116, 65, 127, 115, 113, 54, 2, 0, 11, 11, 11, 11, 226, 2, 1, 6, 127, 32, 1, 40, 2, 0, 33, 3, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 34, 4, 40, 2, 0, 34, 5, 65, 1, 113, 4, 64, 32, 3, 65, 124, 113, 65, 16, 106, 32, 5, 65, 124, 113, 106, 34, 2, 65, 240, 255, 255, 255, 3, 73, 4, 64, 32, 0, 32, 4, 16, 1, 32, 1, 32, 2, 32, 3, 65, 3, 113, 114, 34, 3, 54, 2, 0, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 34, 4, 40, 2, 0, 33, 5, 11, 11, 32, 3, 65, 2, 113, 4, 64, 32, 1, 65, 4, 107, 40, 2, 0, 34, 2, 40, 2, 0, 34, 6, 65, 124, 113, 65, 16, 106, 32, 3, 65, 124, 113, 106, 34, 7, 65, 240, 255, 255, 255, 3, 73, 4, 64, 32, 0, 32, 2, 16, 1, 32, 2, 32, 7, 32, 6, 65, 3, 113, 114, 34, 3, 54, 2, 0, 32, 2, 33, 1, 11, 11, 32, 4, 32, 5, 65, 2, 114, 54, 2, 0, 32, 4, 65, 4, 107, 32, 1, 54, 2, 0, 32, 0, 32, 3, 65, 124, 113, 34, 2, 65, 128, 2, 73, 4, 127, 32, 2, 65, 4, 118, 33, 4, 65, 0, 5, 32, 2, 65, 31, 32, 2, 103, 107, 34, 2, 65, 4, 107, 118, 65, 16, 115, 33, 4, 32, 2, 65, 7, 107, 11, 34, 3, 65, 4, 116, 32, 4, 106, 65, 2, 116, 106, 40, 2, 96, 33, 2, 32, 1, 65, 0, 54, 2, 16, 32, 1, 32, 2, 54, 2, 20, 32, 2, 4, 64, 32, 2, 32, 1, 54, 2, 16, 11, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 32, 1, 54, 2, 96, 32, 0, 32, 0, 40, 2, 0, 65, 1, 32, 3, 116, 114, 54, 2, 0, 32, 0, 32, 3, 65, 2, 116, 106, 32, 0, 32, 3, 65, 2, 116, 106, 40, 2, 4, 65, 1, 32, 4, 116, 114, 54, 2, 4, 11, 119, 1, 1, 127, 32, 2, 2, 127, 32, 0, 40, 2, 160, 12, 34, 2, 4, 64, 32, 2, 32, 1, 65, 16, 107, 70, 4, 64, 32, 2, 40, 2, 0, 33, 3, 32, 1, 65, 16, 107, 33, 1, 11, 11, 32, 1, 11, 107, 34, 2, 65, 48, 73, 4, 64, 15, 11, 32, 1, 32, 3, 65, 2, 113, 32, 2, 65, 32, 107, 65, 1, 114, 114, 54, 2, 0, 32, 1, 65, 0, 54, 2, 16, 32, 1, 65, 0, 54, 2, 20, 32, 1, 32, 2, 106, 65, 16, 107, 34, 2, 65, 2, 54, 2, 0, 32, 0, 32, 2, 54, 2, 160, 12, 32, 0, 32, 1, 16, 2, 11, 155, 1, 1, 3, 127, 35, 0, 34, 0, 69, 4, 64, 65, 1, 63, 0, 34, 0, 74, 4, 127, 65, 1, 32, 0, 107, 64, 0, 65, 0, 72, 5, 65, 0, 11, 4, 64, 0, 11, 65, 176, 3, 34, 0, 65, 0, 54, 2, 0, 65, 208, 15, 65, 0, 54, 2, 0, 3, 64, 32, 1, 65, 23, 73, 4, 64, 32, 1, 65, 2, 116, 65, 176, 3, 106, 65, 0, 54, 2, 4, 65, 0, 33, 2, 3, 64, 32, 2, 65, 16, 73, 4, 64, 32, 1, 65, 4, 116, 32, 2, 106, 65, 2, 116, 65, 176, 3, 106, 65, 0, 54, 2, 96, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 32, 1, 65, 1, 106, 33, 1, 12, 1, 11, 11, 65, 176, 3, 65, 224, 15, 63, 0, 65, 16, 116, 16, 3, 65, 176, 3, 36, 0, 11, 32, 0, 11, 45, 0, 32, 0, 65, 240, 255, 255, 255, 3, 79, 4, 64, 65, 32, 65, 224, 0, 65, 201, 3, 65, 29, 16, 0, 0, 11, 32, 0, 65, 15, 106, 65, 112, 113, 34, 0, 65, 16, 32, 0, 65, 16, 75, 27, 11, 169, 1, 1, 1, 127, 32, 0, 32, 1, 65, 128, 2, 73, 4, 127, 32, 1, 65, 4, 118, 33, 1, 65, 0, 5, 32, 1, 65, 248, 255, 255, 255, 1, 73, 4, 64, 32, 1, 65, 1, 65, 27, 32, 1, 103, 107, 116, 106, 65, 1, 107, 33, 1, 11, 32, 1, 65, 31, 32, 1, 103, 107, 34, 2, 65, 4, 107, 118, 65, 16, 115, 33, 1, 32, 2, 65, 7, 107, 11, 34, 2, 65, 2, 116, 106, 40, 2, 4, 65, 127, 32, 1, 116, 113, 34, 1, 4, 127, 32, 0, 32, 1, 104, 32, 2, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 5, 32, 0, 40, 2, 0, 65, 127, 32, 2, 65, 1, 106, 116, 113, 34, 1, 4, 127, 32, 0, 32, 0, 32, 1, 104, 34, 0, 65, 2, 116, 106, 40, 2, 4, 104, 32, 0, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 5, 65, 0, 11, 11, 11, 111, 1, 1, 127, 63, 0, 34, 2, 32, 1, 65, 248, 255, 255, 255, 1, 73, 4, 127, 32, 1, 65, 1, 65, 27, 32, 1, 103, 107, 116, 65, 1, 107, 106, 5, 32, 1, 11, 65, 16, 32, 0, 40, 2, 160, 12, 32, 2, 65, 16, 116, 65, 16, 107, 71, 116, 106, 65, 255, 255, 3, 106, 65, 128, 128, 124, 113, 65, 16, 118, 34, 1, 32, 2, 32, 1, 74, 27, 64, 0, 65, 0, 72, 4, 64, 32, 1, 64, 0, 65, 0, 72, 4, 64, 0, 11, 11, 32, 0, 32, 2, 65, 16, 116, 63, 0, 65, 16, 116, 16, 3, 11, 113, 1, 2, 127, 32, 1, 40, 2, 0, 34, 3, 65, 124, 113, 32, 2, 107, 34, 4, 65, 32, 79, 4, 64, 32, 1, 32, 2, 32, 3, 65, 2, 113, 114, 54, 2, 0, 32, 2, 32, 1, 65, 16, 106, 106, 34, 1, 32, 4, 65, 16, 107, 65, 1, 114, 54, 2, 0, 32, 0, 32, 1, 16, 2, 5, 32, 1, 32, 3, 65, 126, 113, 54, 2, 0, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 40, 2, 0, 65, 125, 113, 54, 2, 0, 11, 11, 91, 1, 2, 127, 32, 0, 32, 1, 16, 5, 34, 4, 16, 6, 34, 3, 69, 4, 64, 65, 1, 36, 1, 65, 0, 36, 1, 32, 0, 32, 4, 16, 6, 34, 3, 69, 4, 64, 32, 0, 32, 4, 16, 7, 32, 0, 32, 4, 16, 6, 33, 3, 11, 11, 32, 3, 65, 0, 54, 2, 4, 32, 3, 32, 2, 54, 2, 8, 32, 3, 32, 1, 54, 2, 12, 32, 0, 32, 3, 16, 1, 32, 0, 32, 3, 32, 4, 16, 8, 32, 3, 11, 13, 0, 16, 4, 32, 0, 32, 1, 16, 9, 65, 16, 106, 11, 33, 1, 1, 127, 32, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 11, 18, 0, 32, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 16, 52, 11, 11, 140, 3, 1, 1, 127, 2, 64, 32, 1, 69, 13, 0, 32, 0, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 65, 1, 107, 65, 0, 58, 0, 0, 32, 1, 65, 2, 77, 13, 0, 32, 0, 65, 1, 106, 65, 0, 58, 0, 0, 32, 0, 65, 2, 106, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 34, 2, 65, 2, 107, 65, 0, 58, 0, 0, 32, 2, 65, 3, 107, 65, 0, 58, 0, 0, 32, 1, 65, 6, 77, 13, 0, 32, 0, 65, 3, 106, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 65, 4, 107, 65, 0, 58, 0, 0, 32, 1, 65, 8, 77, 13, 0, 32, 1, 65, 0, 32, 0, 107, 65, 3, 113, 34, 1, 107, 33, 2, 32, 0, 32, 1, 106, 34, 0, 65, 0, 54, 2, 0, 32, 0, 32, 2, 65, 124, 113, 34, 1, 106, 65, 4, 107, 65, 0, 54, 2, 0, 32, 1, 65, 8, 77, 13, 0, 32, 0, 65, 4, 106, 65, 0, 54, 2, 0, 32, 0, 65, 8, 106, 65, 0, 54, 2, 0, 32, 0, 32, 1, 106, 34, 2, 65, 12, 107, 65, 0, 54, 2, 0, 32, 2, 65, 8, 107, 65, 0, 54, 2, 0, 32, 1, 65, 24, 77, 13, 0, 32, 0, 65, 12, 106, 65, 0, 54, 2, 0, 32, 0, 65, 16, 106, 65, 0, 54, 2, 0, 32, 0, 65, 20, 106, 65, 0, 54, 2, 0, 32, 0, 65, 24, 106, 65, 0, 54, 2, 0, 32, 0, 32, 1, 106, 34, 2, 65, 28, 107, 65, 0, 54, 2, 0, 32, 2, 65, 24, 107, 65, 0, 54, 2, 0, 32, 2, 65, 20, 107, 65, 0, 54, 2, 0, 32, 2, 65, 16, 107, 65, 0, 54, 2, 0, 32, 0, 32, 0, 65, 4, 113, 65, 24, 106, 34, 2, 106, 33, 0, 32, 1, 32, 2, 107, 33, 1, 3, 64, 32, 1, 65, 32, 79, 4, 64, 32, 0, 66, 0, 55, 3, 0, 32, 0, 65, 8, 106, 66, 0, 55, 3, 0, 32, 0, 65, 16, 106, 66, 0, 55, 3, 0, 32, 0, 65, 24, 106, 66, 0, 55, 3, 0, 32, 1, 65, 32, 107, 33, 1, 32, 0, 65, 32, 106, 33, 0, 12, 1, 11, 11, 11, 11, 178, 1, 1, 3, 127, 32, 1, 65, 240, 255, 255, 255, 3, 32, 2, 118, 75, 4, 64, 65, 144, 1, 65, 192, 1, 65, 23, 65, 56, 16, 0, 0, 11, 32, 1, 32, 2, 116, 34, 3, 65, 0, 16, 10, 34, 2, 32, 3, 16, 13, 32, 0, 69, 4, 64, 65, 12, 65, 2, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 11, 32, 0, 65, 0, 54, 2, 0, 32, 0, 65, 0, 54, 2, 4, 32, 0, 65, 0, 54, 2, 8, 32, 2, 34, 1, 32, 0, 40, 2, 0, 34, 4, 71, 4, 64, 32, 1, 65, 172, 3, 75, 4, 64, 32, 1, 65, 16, 107, 34, 5, 32, 5, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 4, 16, 12, 11, 32, 0, 32, 1, 54, 2, 0, 32, 0, 32, 2, 54, 2, 4, 32, 0, 32, 3, 54, 2, 8, 32, 0, 11, 46, 1, 2, 127, 65, 12, 65, 5, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 65, 128, 2, 65, 3, 16, 14, 11, 9, 0, 65, 63, 32, 0, 121, 167, 107, 11, 49, 1, 2, 127, 65, 63, 32, 1, 121, 167, 107, 33, 2, 3, 64, 65, 63, 32, 0, 121, 167, 107, 32, 2, 107, 34, 3, 65, 0, 78, 4, 64, 32, 0, 32, 1, 32, 3, 172, 134, 133, 33, 0, 12, 1, 11, 11, 32, 0, 11, 40, 0, 32, 1, 32, 0, 40, 2, 8, 79, 4, 64, 65, 128, 2, 65, 192, 2, 65, 163, 1, 65, 44, 16, 0, 0, 11, 32, 1, 32, 0, 40, 2, 4, 106, 65, 0, 58, 0, 0, 11, 38, 0, 32, 1, 32, 0, 40, 2, 8, 79, 4, 64, 65, 128, 2, 65, 192, 2, 65, 152, 1, 65, 44, 16, 0, 0, 11, 32, 1, 32, 0, 40, 2, 4, 106, 45, 0, 0, 11, 254, 5, 2, 1, 127, 4, 126, 32, 0, 69, 4, 64, 65, 232, 0, 65, 6, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 5, 32, 5, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 11, 32, 0, 65, 0, 54, 2, 0, 32, 0, 65, 0, 54, 2, 4, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 24, 32, 0, 66, 0, 55, 3, 32, 32, 0, 66, 0, 55, 3, 40, 32, 0, 66, 0, 55, 3, 48, 32, 0, 66, 0, 55, 3, 56, 32, 0, 66, 0, 55, 3, 64, 32, 0, 66, 0, 55, 3, 72, 32, 0, 66, 0, 55, 3, 80, 32, 0, 66, 0, 55, 3, 88, 32, 0, 66, 0, 55, 3, 96, 32, 0, 32, 2, 173, 55, 3, 80, 32, 0, 32, 3, 173, 55, 3, 88, 65, 12, 65, 4, 16, 10, 34, 2, 65, 172, 3, 75, 4, 64, 32, 2, 65, 16, 107, 34, 3, 32, 3, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 32, 4, 65, 0, 16, 14, 33, 2, 32, 0, 40, 2, 0, 16, 12, 32, 0, 32, 2, 54, 2, 0, 32, 0, 32, 4, 54, 2, 4, 32, 0, 66, 1, 32, 1, 173, 134, 66, 1, 125, 55, 3, 96, 32, 0, 66, 243, 130, 183, 218, 216, 230, 232, 30, 55, 3, 72, 35, 4, 69, 4, 64, 65, 0, 33, 2, 3, 64, 32, 2, 65, 128, 2, 72, 4, 64, 32, 2, 65, 255, 1, 113, 173, 33, 6, 32, 0, 41, 3, 72, 34, 7, 33, 8, 65, 63, 32, 7, 121, 167, 107, 33, 1, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 1, 107, 34, 3, 65, 0, 78, 4, 64, 32, 6, 32, 8, 32, 3, 172, 134, 133, 33, 6, 12, 1, 11, 11, 65, 0, 33, 4, 3, 64, 32, 4, 32, 0, 40, 2, 4, 65, 1, 107, 72, 4, 64, 32, 6, 66, 8, 134, 33, 6, 32, 0, 41, 3, 72, 34, 7, 33, 8, 65, 63, 32, 7, 121, 167, 107, 33, 1, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 1, 107, 34, 3, 65, 0, 78, 4, 64, 32, 6, 32, 8, 32, 3, 172, 134, 133, 33, 6, 12, 1, 11, 11, 32, 4, 65, 1, 106, 33, 4, 12, 1, 11, 11, 35, 6, 40, 2, 4, 32, 2, 65, 3, 116, 106, 32, 6, 55, 3, 0, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 65, 63, 32, 0, 41, 3, 72, 121, 167, 107, 172, 33, 7, 65, 0, 33, 2, 3, 64, 32, 2, 65, 128, 2, 72, 4, 64, 35, 5, 33, 1, 32, 2, 172, 32, 7, 134, 34, 8, 33, 6, 65, 63, 32, 0, 41, 3, 72, 34, 9, 121, 167, 107, 33, 3, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 3, 107, 34, 4, 65, 0, 78, 4, 64, 32, 6, 32, 9, 32, 4, 172, 134, 133, 33, 6, 12, 1, 11, 11, 32, 1, 40, 2, 4, 32, 2, 65, 3, 116, 106, 32, 6, 32, 8, 132, 55, 3, 0, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 65, 1, 36, 4, 11, 32, 0, 66, 0, 55, 3, 24, 32, 0, 66, 0, 55, 3, 32, 65, 0, 33, 2, 3, 64, 32, 2, 32, 0, 40, 2, 4, 72, 4, 64, 32, 0, 40, 2, 0, 32, 2, 16, 18, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 32, 0, 66, 0, 55, 3, 40, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 40, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 1, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 65, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 1, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 6, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 6, 66, 8, 134, 66, 1, 132, 133, 55, 3, 40, 32, 0, 11, 38, 1, 1, 127, 32, 0, 40, 2, 0, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 11, 55, 1, 2, 127, 32, 1, 32, 0, 40, 2, 0, 34, 2, 71, 4, 64, 32, 1, 65, 172, 3, 75, 4, 64, 32, 1, 65, 16, 107, 34, 3, 32, 3, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 16, 12, 11, 32, 0, 32, 1, 54, 2, 0, 11, 7, 0, 32, 0, 40, 2, 4, 11, 9, 0, 32, 0, 32, 1, 54, 2, 4, 11, 7, 0, 32, 0, 40, 2, 8, 11, 9, 0, 32, 0, 32, 1, 54, 2, 8, 11, 7, 0, 32, 0, 41, 3, 16, 11, 9, 0, 32, 0, 32, 1, 55, 3, 16, 11, 7, 0, 32, 0, 41, 3, 24, 11, 9, 0, 32, 0, 32, 1, 55, 3, 24, 11, 7, 0, 32, 0, 41, 3, 32, 11, 9, 0, 32, 0, 32, 1, 55, 3, 32, 11, 7, 0, 32, 0, 41, 3, 40, 11, 9, 0, 32, 0, 32, 1, 55, 3, 40, 11, 7, 0, 32, 0, 41, 3, 48, 11, 9, 0, 32, 0, 32, 1, 55, 3, 48, 11, 7, 0, 32, 0, 41, 3, 56, 11, 9, 0, 32, 0, 32, 1, 55, 3, 56, 11, 7, 0, 32, 0, 41, 3, 64, 11, 9, 0, 32, 0, 32, 1, 55, 3, 64, 11, 7, 0, 32, 0, 41, 3, 72, 11, 9, 0, 32, 0, 32, 1, 55, 3, 72, 11, 7, 0, 32, 0, 41, 3, 80, 11, 9, 0, 32, 0, 32, 1, 55, 3, 80, 11, 7, 0, 32, 0, 41, 3, 88, 11, 9, 0, 32, 0, 32, 1, 55, 3, 88, 11, 7, 0, 32, 0, 41, 3, 96, 11, 9, 0, 32, 0, 32, 1, 55, 3, 96, 11, 172, 4, 2, 5, 127, 1, 126, 32, 2, 65, 172, 3, 75, 4, 64, 32, 2, 65, 16, 107, 34, 4, 32, 4, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 33, 4, 65, 0, 33, 2, 32, 1, 40, 2, 8, 33, 5, 32, 1, 40, 2, 4, 33, 6, 3, 64, 2, 127, 65, 0, 33, 3, 3, 64, 32, 3, 32, 5, 72, 4, 64, 32, 3, 32, 6, 106, 45, 0, 0, 33, 1, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 7, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 32, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 7, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 8, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 1, 173, 32, 8, 66, 8, 134, 132, 133, 55, 3, 40, 32, 0, 32, 0, 41, 3, 16, 66, 1, 124, 55, 3, 16, 32, 0, 32, 0, 41, 3, 24, 66, 1, 124, 55, 3, 24, 32, 0, 41, 3, 16, 32, 0, 41, 3, 80, 90, 4, 127, 32, 0, 41, 3, 40, 32, 0, 41, 3, 96, 131, 80, 5, 65, 0, 11, 4, 127, 65, 1, 5, 32, 0, 41, 3, 16, 32, 0, 41, 3, 88, 90, 11, 4, 64, 32, 0, 32, 0, 41, 3, 32, 55, 3, 48, 32, 0, 32, 0, 41, 3, 16, 55, 3, 56, 32, 0, 32, 0, 41, 3, 40, 55, 3, 64, 65, 0, 33, 1, 3, 64, 32, 1, 32, 0, 40, 2, 4, 72, 4, 64, 32, 0, 40, 2, 0, 32, 1, 16, 18, 32, 1, 65, 1, 106, 33, 1, 12, 1, 11, 11, 32, 0, 66, 0, 55, 3, 40, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 40, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 1, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 65, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 1, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 8, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 8, 66, 8, 134, 66, 1, 132, 133, 55, 3, 40, 32, 3, 65, 1, 106, 12, 3, 11, 32, 3, 65, 1, 106, 33, 3, 12, 1, 11, 11, 65, 127, 11, 34, 1, 65, 0, 78, 4, 64, 32, 5, 32, 1, 107, 33, 5, 32, 1, 32, 6, 106, 33, 6, 32, 2, 34, 1, 65, 1, 106, 33, 2, 32, 4, 40, 2, 4, 32, 1, 65, 2, 116, 106, 32, 0, 41, 3, 56, 62, 2, 0, 12, 1, 11, 11, 32, 4, 11, 10, 0, 16, 15, 36, 5, 16, 15, 36, 6, 11, 3, 0, 1, 11, 73, 1, 2, 127, 32, 0, 40, 2, 4, 34, 1, 65, 255, 255, 255, 255, 0, 113, 34, 2, 65, 1, 70, 4, 64, 32, 0, 65, 16, 106, 16, 53, 32, 0, 32, 0, 40, 2, 0, 65, 1, 114, 54, 2, 0, 35, 0, 32, 0, 16, 2, 5, 32, 0, 32, 2, 65, 1, 107, 32, 1, 65, 128, 128, 128, 128, 127, 113, 114, 54, 2, 4, 11, 11, 58, 0, 2, 64, 2, 64, 2, 64, 32, 0, 65, 8, 107, 40, 2, 0, 14, 7, 0, 0, 1, 1, 1, 1, 1, 2, 11, 15, 11, 32, 0, 40, 2, 0, 34, 0, 4, 64, 32, 0, 65, 172, 3, 79, 4, 64, 32, 0, 65, 16, 107, 16, 52, 11, 11, 15, 11, 0, 11, 11, 137, 3, 7, 0, 65, 16, 11, 55, 40, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 40, 0, 0, 0, 97, 0, 108, 0, 108, 0, 111, 0, 99, 0, 97, 0, 116, 0, 105, 0, 111, 0, 110, 0, 32, 0, 116, 0, 111, 0, 111, 0, 32, 0, 108, 0, 97, 0, 114, 0, 103, 0, 101, 0, 65, 208, 0, 11, 45, 30, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 30, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 114, 0, 116, 0, 47, 0, 116, 0, 108, 0, 115, 0, 102, 0, 46, 0, 116, 0, 115, 0, 65, 128, 1, 11, 43, 28, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 28, 0, 0, 0, 73, 0, 110, 0, 118, 0, 97, 0, 108, 0, 105, 0, 100, 0, 32, 0, 108, 0, 101, 0, 110, 0, 103, 0, 116, 0, 104, 0, 65, 176, 1, 11, 53, 38, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 38, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 97, 0, 114, 0, 114, 0, 97, 0, 121, 0, 98, 0, 117, 0, 102, 0, 102, 0, 101, 0, 114, 0, 46, 0, 116, 0, 115, 0, 65, 240, 1, 11, 51, 36, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 36, 0, 0, 0, 73, 0, 110, 0, 100, 0, 101, 0, 120, 0, 32, 0, 111, 0, 117, 0, 116, 0, 32, 0, 111, 0, 102, 0, 32, 0, 114, 0, 97, 0, 110, 0, 103, 0, 101, 0, 65, 176, 2, 11, 51, 36, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 36, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 116, 0, 121, 0, 112, 0, 101, 0, 100, 0, 97, 0, 114, 0, 114, 0, 97, 0, 121, 0, 46, 0, 116, 0, 115, 0, 65, 240, 2, 11, 53, 7, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 145, 4, 0, 0, 2, 0, 0, 0, 49, 0, 0, 0, 2, 0, 0, 0, 17, 1, 0, 0, 2, 0, 0, 0, 16, 0, 34, 16, 115, 111, 117, 114, 99, 101, 77, 97, 112, 112, 105, 110, 103, 85, 82, 76, 16, 46, 47, 114, 97, 98, 105, 110, 46, 119, 97, 115, 109, 46, 109, 97, 112]);
      return instantiate(new Response(new Blob([wasm], { type: "application/wasm" })), imp);
    }
    module.exports = loadWebAssembly;
  }
});

// node_modules/rabin-wasm/src/index.js
var require_src = __commonJS({
  "node_modules/rabin-wasm/src/index.js"(exports, module) {
    var Rabin = require_rabin();
    var getRabin = require_rabin_wasm();
    var create2 = async (avg, min, max, windowSize, polynomial) => {
      const compiled = await getRabin();
      return new Rabin(compiled, avg, min, max, windowSize, polynomial);
    };
    module.exports = {
      Rabin,
      create: create2
    };
  }
});

// node_modules/it-batch/dist/src/index.js
function isAsyncIterable(thing) {
  return thing[Symbol.asyncIterator] != null;
}
function batch(source, size = 1) {
  size = Number(size);
  if (isAsyncIterable(source)) {
    return async function* () {
      let things = [];
      if (size < 1) {
        size = 1;
      }
      if (size !== Math.round(size)) {
        throw new Error("Batch size must be an integer");
      }
      for await (const thing of source) {
        things.push(thing);
        while (things.length >= size) {
          yield things.slice(0, size);
          things = things.slice(size);
        }
      }
      while (things.length > 0) {
        yield things.slice(0, size);
        things = things.slice(size);
      }
    }();
  }
  return function* () {
    let things = [];
    if (size < 1) {
      size = 1;
    }
    if (size !== Math.round(size)) {
      throw new Error("Batch size must be an integer");
    }
    for (const thing of source) {
      things.push(thing);
      while (things.length >= size) {
        yield things.slice(0, size);
        things = things.slice(size);
      }
    }
    while (things.length > 0) {
      yield things.slice(0, size);
      things = things.slice(size);
    }
  }();
}
var src_default5 = batch;

// node_modules/it-parallel-batch/dist/src/index.js
async function* parallelBatch(source, size = 1) {
  for await (const tasks of src_default5(source, size)) {
    const things = tasks.map(async (p) => {
      return p().then((value) => ({ ok: true, value }), (err) => ({ ok: false, err }));
    });
    for (let i = 0; i < things.length; i++) {
      const result = await things[i];
      if (result.ok) {
        yield result.value;
      } else {
        throw result.err;
      }
    }
  }
}

// node_modules/ipfs-unixfs-importer/dist/src/chunker/fixed-size.js
var DEFAULT_CHUNK_SIZE = 262144;
var fixedSize = (options = {}) => {
  const chunkSize = options.chunkSize ?? DEFAULT_CHUNK_SIZE;
  return async function* fixedSizeChunker(source) {
    let list = new Uint8ArrayList();
    let currentLength = 0;
    let emitted = false;
    for await (const buffer of source) {
      list.append(buffer);
      currentLength += buffer.length;
      while (currentLength >= chunkSize) {
        yield list.slice(0, chunkSize);
        emitted = true;
        if (chunkSize === list.length) {
          list = new Uint8ArrayList();
          currentLength = 0;
        } else {
          const newBl = new Uint8ArrayList();
          newBl.append(list.sublist(chunkSize));
          list = newBl;
          currentLength -= chunkSize;
        }
      }
    }
    if (!emitted || currentLength > 0) {
      yield list.subarray(0, currentLength);
    }
  };
};

// node_modules/ipfs-unixfs/dist/src/errors.js
var _InvalidTypeError = class _InvalidTypeError extends Error {
  constructor(message2 = "Invalid type") {
    super(message2);
    __publicField(this, "name", _InvalidTypeError.name);
    __publicField(this, "code", _InvalidTypeError.code);
  }
};
__publicField(_InvalidTypeError, "name", "InvalidTypeError");
__publicField(_InvalidTypeError, "code", "ERR_INVALID_TYPE");
var InvalidTypeError = _InvalidTypeError;

// node_modules/ipfs-unixfs/dist/src/unixfs.js
var Data;
(function(Data2) {
  let DataType;
  (function(DataType2) {
    DataType2["Raw"] = "Raw";
    DataType2["Directory"] = "Directory";
    DataType2["File"] = "File";
    DataType2["Metadata"] = "Metadata";
    DataType2["Symlink"] = "Symlink";
    DataType2["HAMTShard"] = "HAMTShard";
  })(DataType = Data2.DataType || (Data2.DataType = {}));
  let __DataTypeValues;
  (function(__DataTypeValues2) {
    __DataTypeValues2[__DataTypeValues2["Raw"] = 0] = "Raw";
    __DataTypeValues2[__DataTypeValues2["Directory"] = 1] = "Directory";
    __DataTypeValues2[__DataTypeValues2["File"] = 2] = "File";
    __DataTypeValues2[__DataTypeValues2["Metadata"] = 3] = "Metadata";
    __DataTypeValues2[__DataTypeValues2["Symlink"] = 4] = "Symlink";
    __DataTypeValues2[__DataTypeValues2["HAMTShard"] = 5] = "HAMTShard";
  })(__DataTypeValues || (__DataTypeValues = {}));
  (function(DataType2) {
    DataType2.codec = () => {
      return enumeration(__DataTypeValues);
    };
  })(DataType = Data2.DataType || (Data2.DataType = {}));
  let _codec;
  Data2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.Type != null) {
          w.uint32(8);
          Data2.DataType.codec().encode(obj.Type, w);
        }
        if (obj.Data != null) {
          w.uint32(18);
          w.bytes(obj.Data);
        }
        if (obj.filesize != null) {
          w.uint32(24);
          w.uint64(obj.filesize);
        }
        if (obj.blocksizes != null) {
          for (const value of obj.blocksizes) {
            w.uint32(32);
            w.uint64(value);
          }
        }
        if (obj.hashType != null) {
          w.uint32(40);
          w.uint64(obj.hashType);
        }
        if (obj.fanout != null) {
          w.uint32(48);
          w.uint64(obj.fanout);
        }
        if (obj.mode != null) {
          w.uint32(56);
          w.uint32(obj.mode);
        }
        if (obj.mtime != null) {
          w.uint32(66);
          UnixTime.codec().encode(obj.mtime, w);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length) => {
        const obj = {
          blocksizes: []
        };
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.Type = Data2.DataType.codec().decode(reader);
              break;
            case 2:
              obj.Data = reader.bytes();
              break;
            case 3:
              obj.filesize = reader.uint64();
              break;
            case 4:
              obj.blocksizes.push(reader.uint64());
              break;
            case 5:
              obj.hashType = reader.uint64();
              break;
            case 6:
              obj.fanout = reader.uint64();
              break;
            case 7:
              obj.mode = reader.uint32();
              break;
            case 8:
              obj.mtime = UnixTime.codec().decode(reader, reader.uint32());
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  Data2.encode = (obj) => {
    return encodeMessage(obj, Data2.codec());
  };
  Data2.decode = (buf) => {
    return decodeMessage(buf, Data2.codec());
  };
})(Data || (Data = {}));
var UnixTime;
(function(UnixTime2) {
  let _codec;
  UnixTime2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.Seconds != null) {
          w.uint32(8);
          w.int64(obj.Seconds);
        }
        if (obj.FractionalNanoseconds != null) {
          w.uint32(21);
          w.fixed32(obj.FractionalNanoseconds);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length) => {
        const obj = {};
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.Seconds = reader.int64();
              break;
            case 2:
              obj.FractionalNanoseconds = reader.fixed32();
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  UnixTime2.encode = (obj) => {
    return encodeMessage(obj, UnixTime2.codec());
  };
  UnixTime2.decode = (buf) => {
    return decodeMessage(buf, UnixTime2.codec());
  };
})(UnixTime || (UnixTime = {}));
var Metadata;
(function(Metadata2) {
  let _codec;
  Metadata2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.MimeType != null) {
          w.uint32(10);
          w.string(obj.MimeType);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length) => {
        const obj = {};
        const end = length == null ? reader.len : reader.pos + length;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.MimeType = reader.string();
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  Metadata2.encode = (obj) => {
    return encodeMessage(obj, Metadata2.codec());
  };
  Metadata2.decode = (buf) => {
    return decodeMessage(buf, Metadata2.codec());
  };
})(Metadata || (Metadata = {}));

// node_modules/ipfs-unixfs/dist/src/index.js
var types = {
  Raw: "raw",
  Directory: "directory",
  File: "file",
  Metadata: "metadata",
  Symlink: "symlink",
  HAMTShard: "hamt-sharded-directory"
};
var dirTypes = [
  "directory",
  "hamt-sharded-directory"
];
var DEFAULT_FILE_MODE = parseInt("0644", 8);
var DEFAULT_DIRECTORY_MODE = parseInt("0755", 8);
var UnixFS = class _UnixFS {
  constructor(options = {
    type: "file"
  }) {
    __publicField(this, "type");
    __publicField(this, "data");
    __publicField(this, "blockSizes");
    __publicField(this, "hashType");
    __publicField(this, "fanout");
    __publicField(this, "mtime");
    __publicField(this, "_mode");
    __publicField(this, "_originalMode");
    const { type, data, blockSizes, hashType, fanout, mtime, mode } = options;
    if (type != null && !Object.values(types).includes(type)) {
      throw new InvalidTypeError("Type: " + type + " is not valid");
    }
    this.type = type ?? "file";
    this.data = data;
    this.hashType = hashType;
    this.fanout = fanout;
    this.blockSizes = blockSizes ?? [];
    this._originalMode = 0;
    this.mode = mode;
    this.mtime = mtime;
  }
  /**
   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md
   */
  static unmarshal(marshaled) {
    const message2 = Data.decode(marshaled);
    const data = new _UnixFS({
      type: types[message2.Type != null ? message2.Type.toString() : "File"],
      data: message2.Data,
      blockSizes: message2.blocksizes,
      mode: message2.mode,
      mtime: message2.mtime != null ? {
        secs: message2.mtime.Seconds ?? 0n,
        nsecs: message2.mtime.FractionalNanoseconds
      } : void 0,
      fanout: message2.fanout
    });
    data._originalMode = message2.mode ?? 0;
    return data;
  }
  set mode(mode) {
    if (mode == null) {
      this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE;
    } else {
      this._mode = mode & 4095;
    }
  }
  get mode() {
    return this._mode;
  }
  isDirectory() {
    return dirTypes.includes(this.type);
  }
  addBlockSize(size) {
    this.blockSizes.push(size);
  }
  removeBlockSize(index) {
    this.blockSizes.splice(index, 1);
  }
  /**
   * Returns `0n` for directories or `data.length + sum(blockSizes)` for everything else
   */
  fileSize() {
    if (this.isDirectory()) {
      return 0n;
    }
    let sum = 0n;
    this.blockSizes.forEach((size) => {
      sum += size;
    });
    if (this.data != null) {
      sum += BigInt(this.data.length);
    }
    return sum;
  }
  /**
   * encode to protobuf Uint8Array
   */
  marshal() {
    let type;
    switch (this.type) {
      case "raw":
        type = Data.DataType.Raw;
        break;
      case "directory":
        type = Data.DataType.Directory;
        break;
      case "file":
        type = Data.DataType.File;
        break;
      case "metadata":
        type = Data.DataType.Metadata;
        break;
      case "symlink":
        type = Data.DataType.Symlink;
        break;
      case "hamt-sharded-directory":
        type = Data.DataType.HAMTShard;
        break;
      default:
        throw new InvalidTypeError(`Type: ${type} is not valid`);
    }
    let data = this.data;
    if (this.data == null || this.data.length === 0) {
      data = void 0;
    }
    let mode;
    if (this.mode != null) {
      mode = this._originalMode & 4294963200 | (this.mode ?? 0);
      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {
        mode = void 0;
      }
      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {
        mode = void 0;
      }
    }
    let mtime;
    if (this.mtime != null) {
      mtime = {
        Seconds: this.mtime.secs,
        FractionalNanoseconds: this.mtime.nsecs
      };
    }
    return Data.encode({
      Type: type,
      Data: data,
      filesize: this.isDirectory() ? void 0 : this.fileSize(),
      blocksizes: this.blockSizes,
      hashType: this.hashType,
      fanout: this.fanout,
      mode,
      mtime
    });
  }
};

// node_modules/ipfs-unixfs-importer/dist/src/utils/persist.js
var persist = async (buffer, blockstore, options) => {
  if (options.codec == null) {
    options.codec = src_exports;
  }
  const multihash = await sha256.digest(buffer);
  const cid = CID.create(options.cidVersion, options.codec.code, multihash);
  await blockstore.put(cid, buffer, options);
  return cid;
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/buffer-importer.js
function defaultBufferImporter(options) {
  return async function* bufferImporter(file, blockstore) {
    let bytesWritten = 0n;
    for await (let block of file.content) {
      yield async () => {
        var _a;
        let unixfs2;
        const opts = {
          codec: src_exports,
          cidVersion: options.cidVersion,
          onProgress: options.onProgress
        };
        if (options.rawLeaves) {
          opts.codec = raw_exports;
          opts.cidVersion = 1;
        } else {
          unixfs2 = new UnixFS({
            type: options.leafType,
            data: block
          });
          block = encode({
            Data: unixfs2.marshal(),
            Links: []
          });
        }
        const cid = await persist(block, blockstore, opts);
        bytesWritten += BigInt(block.byteLength);
        (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:importer:progress:file:write", {
          bytesWritten,
          cid,
          path: file.path
        }));
        return {
          cid,
          unixfs: unixfs2,
          size: BigInt(block.length),
          block
        };
      };
    }
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/errors.js
var _InvalidParametersError = class _InvalidParametersError extends Error {
  constructor(message2 = "Invalid parameters") {
    super(message2);
    __publicField(this, "name", _InvalidParametersError.name);
    __publicField(this, "code", _InvalidParametersError.code);
  }
};
__publicField(_InvalidParametersError, "name", "InvalidParametersError");
__publicField(_InvalidParametersError, "code", "ERR_INVALID_PARAMS");
var InvalidParametersError = _InvalidParametersError;
var _InvalidContentError = class _InvalidContentError extends Error {
  constructor(message2 = "Invalid content") {
    super(message2);
    __publicField(this, "name", _InvalidContentError.name);
    __publicField(this, "code", _InvalidContentError.code);
  }
};
__publicField(_InvalidContentError, "name", "InvalidContentError");
__publicField(_InvalidContentError, "code", "ERR_INVALID_CONTENT");
var InvalidContentError = _InvalidContentError;

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/dir.js
var dirBuilder = async (dir, blockstore, options) => {
  const unixfs2 = new UnixFS({
    type: "directory",
    mtime: dir.mtime,
    mode: dir.mode
  });
  const block = encode(prepare({ Data: unixfs2.marshal() }));
  const cid = await persist(block, blockstore, options);
  const path = dir.path;
  return {
    cid,
    path,
    unixfs: unixfs2,
    size: BigInt(block.length),
    originalPath: dir.originalPath,
    block
  };
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/file.js
async function* buildFileBatch(file, blockstore, options) {
  let count = -1;
  let previous;
  for await (const entry of parallelBatch(options.bufferImporter(file, blockstore), options.blockWriteConcurrency)) {
    count++;
    if (count === 0) {
      previous = {
        ...entry,
        single: true
      };
      continue;
    } else if (count === 1 && previous != null) {
      yield {
        ...previous,
        block: void 0,
        single: void 0
      };
      previous = void 0;
    }
    yield {
      ...entry,
      block: void 0
    };
  }
  if (previous != null) {
    yield previous;
  }
}
function isSingleBlockImport(result) {
  return result.single === true;
}
var reduce = (file, blockstore, options) => {
  const reducer = async function(leaves) {
    var _a, _b;
    if (leaves.length === 1 && isSingleBlockImport(leaves[0]) && options.reduceSingleLeafToSelf) {
      const leaf = leaves[0];
      let node2 = leaf.block;
      if (isSingleBlockImport(leaf) && (file.mtime !== void 0 || file.mode !== void 0)) {
        leaf.unixfs = new UnixFS({
          type: "file",
          mtime: file.mtime,
          mode: file.mode,
          data: leaf.block
        });
        node2 = { Data: leaf.unixfs.marshal(), Links: [] };
        leaf.block = encode(prepare(node2));
        leaf.cid = await persist(leaf.block, blockstore, {
          ...options,
          cidVersion: options.cidVersion
        });
        leaf.size = BigInt(leaf.block.length);
      }
      (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:importer:progress:file:layout", {
        cid: leaf.cid,
        path: leaf.originalPath
      }));
      return {
        cid: leaf.cid,
        path: file.path,
        unixfs: leaf.unixfs,
        size: leaf.size,
        originalPath: leaf.originalPath
      };
    }
    const f = new UnixFS({
      type: "file",
      mtime: file.mtime,
      mode: file.mode
    });
    const links = leaves.filter((leaf) => {
      var _a2, _b2;
      if (leaf.cid.code === code2 && leaf.size > 0) {
        return true;
      }
      if (leaf.unixfs != null && leaf.unixfs.data == null && leaf.unixfs.fileSize() > 0n) {
        return true;
      }
      return Boolean((_b2 = (_a2 = leaf.unixfs) == null ? void 0 : _a2.data) == null ? void 0 : _b2.length);
    }).map((leaf) => {
      var _a2, _b2;
      if (leaf.cid.code === code2) {
        f.addBlockSize(leaf.size);
        return {
          Name: "",
          Tsize: Number(leaf.size),
          Hash: leaf.cid
        };
      }
      if (((_a2 = leaf.unixfs) == null ? void 0 : _a2.data) == null) {
        f.addBlockSize(((_b2 = leaf.unixfs) == null ? void 0 : _b2.fileSize()) ?? 0n);
      } else {
        f.addBlockSize(BigInt(leaf.unixfs.data.length));
      }
      return {
        Name: "",
        Tsize: Number(leaf.size),
        Hash: leaf.cid
      };
    });
    const node = {
      Data: f.marshal(),
      Links: links
    };
    const block = encode(prepare(node));
    const cid = await persist(block, blockstore, options);
    (_b = options.onProgress) == null ? void 0 : _b.call(options, new CustomProgressEvent("unixfs:importer:progress:file:layout", {
      cid,
      path: file.originalPath
    }));
    return {
      cid,
      path: file.path,
      unixfs: f,
      size: BigInt(block.length + node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), 0)),
      originalPath: file.originalPath,
      block
    };
  };
  return reducer;
};
var fileBuilder = async (file, block, options) => {
  return options.layout(buildFileBatch(file, block, options), reduce(file, block, options));
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/index.js
function isIterable(thing) {
  return Symbol.iterator in thing;
}
function isAsyncIterable2(thing) {
  return Symbol.asyncIterator in thing;
}
function contentAsAsyncIterable(content) {
  try {
    if (content instanceof Uint8Array) {
      return async function* () {
        yield content;
      }();
    } else if (isIterable(content)) {
      return async function* () {
        yield* content;
      }();
    } else if (isAsyncIterable2(content)) {
      return content;
    }
  } catch {
    throw new InvalidContentError("Content was invalid");
  }
  throw new InvalidContentError("Content was invalid");
}
function defaultDagBuilder(options) {
  return async function* dagBuilder(source, blockstore) {
    for await (const entry of source) {
      let originalPath;
      if (entry.path != null) {
        originalPath = entry.path;
        entry.path = entry.path.split("/").filter((path) => path != null && path !== ".").join("/");
      }
      if (isFileCandidate(entry)) {
        const file = {
          path: entry.path,
          mtime: entry.mtime,
          mode: entry.mode,
          content: async function* () {
            var _a;
            let bytesRead = 0n;
            for await (const chunk of options.chunker(options.chunkValidator(contentAsAsyncIterable(entry.content)))) {
              const currentChunkSize = BigInt(chunk.byteLength);
              bytesRead += currentChunkSize;
              (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:importer:progress:file:read", {
                bytesRead,
                chunkSize: currentChunkSize,
                path: entry.path
              }));
              yield chunk;
            }
          }(),
          originalPath
        };
        yield async () => fileBuilder(file, blockstore, options);
      } else if (entry.path != null) {
        const dir = {
          path: entry.path,
          mtime: entry.mtime,
          mode: entry.mode,
          originalPath
        };
        yield async () => dirBuilder(dir, blockstore, options);
      } else {
        throw new Error("Import candidate must have content or path or both");
      }
    }
  };
}
function isFileCandidate(entry) {
  return entry.content != null;
}

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/validate-chunks.js
var defaultChunkValidator = () => {
  return async function* validateChunks(source) {
    for await (const content of source) {
      if (content.length === void 0) {
        throw new InvalidContentError("Content was invalid");
      }
      if (typeof content === "string" || content instanceof String) {
        yield fromString(content.toString());
      } else if (Array.isArray(content)) {
        yield Uint8Array.from(content);
      } else if (content instanceof Uint8Array) {
        yield content;
      } else {
        throw new InvalidContentError("Content was invalid");
      }
    }
  };
};

// node_modules/ipfs-unixfs-importer/dist/src/layout/balanced.js
var DEFAULT_MAX_CHILDREN_PER_NODE = 174;
function balanced(options) {
  const maxChildrenPerNode = (options == null ? void 0 : options.maxChildrenPerNode) ?? DEFAULT_MAX_CHILDREN_PER_NODE;
  return async function balancedLayout(source, reduce2) {
    const roots = [];
    for await (const chunked of src_default5(source, maxChildrenPerNode)) {
      roots.push(await reduce2(chunked));
    }
    if (roots.length > 1) {
      return balancedLayout(roots, reduce2);
    }
    return roots[0];
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/dir.js
var Dir = class {
  constructor(props, options) {
    __publicField(this, "options");
    __publicField(this, "root");
    __publicField(this, "dir");
    __publicField(this, "path");
    __publicField(this, "dirty");
    __publicField(this, "flat");
    __publicField(this, "parent");
    __publicField(this, "parentKey");
    __publicField(this, "unixfs");
    __publicField(this, "mode");
    __publicField(this, "mtime");
    __publicField(this, "cid");
    __publicField(this, "size");
    __publicField(this, "nodeSize");
    this.options = options ?? {};
    this.root = props.root;
    this.dir = props.dir;
    this.path = props.path;
    this.dirty = props.dirty;
    this.flat = props.flat;
    this.parent = props.parent;
    this.parentKey = props.parentKey;
    this.unixfs = props.unixfs;
    this.mode = props.mode;
    this.mtime = props.mtime;
  }
};
var CID_V0 = CID.parse("QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn");
var CID_V1 = CID.parse("zdj7WbTaiJT1fgatdet9Ei9iDB5hdCxkbVyhyh8YTUnXMiwYi");

// node_modules/ipfs-unixfs-importer/dist/src/dir-flat.js
var DirFlat = class extends Dir {
  constructor(props, options) {
    super(props, options);
    __publicField(this, "_children");
    this._children = /* @__PURE__ */ new Map();
  }
  async put(name, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    this._children.set(name, value);
  }
  async get(name) {
    return Promise.resolve(this._children.get(name));
  }
  childCount() {
    return this._children.size;
  }
  directChildrenCount() {
    return this.childCount();
  }
  onlyChild() {
    return this._children.values().next().value;
  }
  async *eachChildSeries() {
    for (const [key, child] of this._children.entries()) {
      yield {
        key,
        child
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = 0;
    for (const [name, child] of this._children.entries()) {
      if (child.size != null && child.cid != null) {
        this.nodeSize += name.length + (this.options.cidVersion === 1 ? CID_V1.bytes.byteLength : CID_V0.bytes.byteLength);
      }
    }
    return this.nodeSize;
  }
  async *flush(block) {
    const links = [];
    for (const [name, child] of this._children.entries()) {
      let result = child;
      if (child instanceof Dir) {
        for await (const entry of child.flush(block)) {
          result = entry;
          yield entry;
        }
      }
      if (result.size != null && result.cid != null) {
        links.push({
          Name: name,
          Tsize: Number(result.size),
          Hash: result.cid
        });
      }
    }
    const unixfs2 = new UnixFS({
      type: "directory",
      mtime: this.mtime,
      mode: this.mode
    });
    const node = { Data: unixfs2.marshal(), Links: links };
    const buffer = encode(prepare(node));
    const cid = await persist(buffer, block, this.options);
    const size = buffer.length + node.Links.reduce(
      /**
       * @param {number} acc
       * @param {PBLink} curr
       */
      (acc, curr) => acc + (curr.Tsize ?? 0),
      0
    );
    this.cid = cid;
    this.size = size;
    yield {
      cid,
      unixfs: unixfs2,
      path: this.path,
      size: BigInt(size)
    };
  }
};

// node_modules/@multiformats/murmur3/src/index.js
var import_murmurhash3js_revisited = __toESM(require_murmurhash3js_revisited());
function fromNumberTo32BitBuf(number) {
  const bytes = new Array(4);
  for (let i = 0; i < 4; i++) {
    bytes[i] = number & 255;
    number = number >> 8;
  }
  return new Uint8Array(bytes);
}
var murmur332 = from({
  name: "murmur3-32",
  code: 35,
  encode: (input) => fromNumberTo32BitBuf(import_murmurhash3js_revisited.default.x86.hash32(input))
});
var murmur3128 = from({
  name: "murmur3-128",
  code: 34,
  encode: (input) => bytes_exports.fromHex(import_murmurhash3js_revisited.default.x64.hash128(input))
});
var murmur364 = from({
  name: "murmur3-x64-64",
  code: 34,
  encode: (input) => bytes_exports.fromHex(import_murmurhash3js_revisited.default.x64.hash128(input)).subarray(0, 8)
});

// node_modules/hamt-sharding/dist/src/bucket.js
var import_sparse_array = __toESM(require_sparse_array(), 1);
var Bucket = class _Bucket {
  constructor(options, parent, posAtParent = 0) {
    __publicField(this, "_options");
    __publicField(this, "_popCount");
    __publicField(this, "_parent");
    __publicField(this, "_posAtParent");
    __publicField(this, "_children");
    __publicField(this, "key");
    this._options = options;
    this._popCount = 0;
    this._parent = parent;
    this._posAtParent = posAtParent;
    this._children = new import_sparse_array.default();
    this.key = null;
  }
  async put(key, value) {
    const place = await this._findNewBucketAndPos(key);
    place.bucket._putAt(place, key, value);
  }
  async get(key) {
    const child = await this._findChild(key);
    if (child != null) {
      return child.value;
    }
  }
  async del(key) {
    const place = await this._findPlace(key);
    const child = place.bucket._at(place.pos);
    if (child != null && child.key === key) {
      place.bucket._delAt(place.pos);
    }
  }
  leafCount() {
    const children = this._children.compactArray();
    return children.reduce((acc, child) => {
      if (child instanceof _Bucket) {
        return acc + child.leafCount();
      }
      return acc + 1;
    }, 0);
  }
  childrenCount() {
    return this._children.length;
  }
  onlyChild() {
    return this._children.get(0);
  }
  *eachLeafSeries() {
    const children = this._children.compactArray();
    for (const child of children) {
      if (child instanceof _Bucket) {
        yield* child.eachLeafSeries();
      } else {
        yield child;
      }
    }
  }
  serialize(map, reduce2) {
    const acc = [];
    return reduce2(this._children.reduce((acc2, child, index) => {
      if (child != null) {
        if (child instanceof _Bucket) {
          acc2.push(child.serialize(map, reduce2));
        } else {
          acc2.push(map(child, index));
        }
      }
      return acc2;
    }, acc));
  }
  async asyncTransform(asyncMap, asyncReduce) {
    return asyncTransformBucket(this, asyncMap, asyncReduce);
  }
  toJSON() {
    return this.serialize(mapNode, reduceNodes);
  }
  prettyPrint() {
    return JSON.stringify(this.toJSON(), null, "  ");
  }
  tableSize() {
    return Math.pow(2, this._options.bits);
  }
  async _findChild(key) {
    const result = await this._findPlace(key);
    const child = result.bucket._at(result.pos);
    if (child instanceof _Bucket) {
      return void 0;
    }
    if (child != null && child.key === key) {
      return child;
    }
  }
  async _findPlace(key) {
    const hashValue = this._options.hash(typeof key === "string" ? fromString(key) : key);
    const index = await hashValue.take(this._options.bits);
    const child = this._children.get(index);
    if (child instanceof _Bucket) {
      return child._findPlace(hashValue);
    }
    return {
      bucket: this,
      pos: index,
      hash: hashValue,
      existingChild: child
    };
  }
  async _findNewBucketAndPos(key) {
    const place = await this._findPlace(key);
    if (place.existingChild != null && place.existingChild.key !== key) {
      const bucket = new _Bucket(this._options, place.bucket, place.pos);
      place.bucket._putObjectAt(place.pos, bucket);
      const newPlace = await bucket._findPlace(place.existingChild.hash);
      newPlace.bucket._putAt(newPlace, place.existingChild.key, place.existingChild.value);
      return bucket._findNewBucketAndPos(place.hash);
    }
    return place;
  }
  _putAt(place, key, value) {
    this._putObjectAt(place.pos, {
      key,
      value,
      hash: place.hash
    });
  }
  _putObjectAt(pos, object) {
    if (this._children.get(pos) == null) {
      this._popCount++;
    }
    this._children.set(pos, object);
  }
  _delAt(pos) {
    if (pos === -1) {
      throw new Error("Invalid position");
    }
    if (this._children.get(pos) != null) {
      this._popCount--;
    }
    this._children.unset(pos);
    this._level();
  }
  _level() {
    if (this._parent != null && this._popCount <= 1) {
      if (this._popCount === 1) {
        const onlyChild = this._children.find(exists);
        if (onlyChild != null && !(onlyChild instanceof _Bucket)) {
          const hash = onlyChild.hash;
          hash.untake(this._options.bits);
          const place = {
            pos: this._posAtParent,
            hash,
            bucket: this._parent
          };
          this._parent._putAt(place, onlyChild.key, onlyChild.value);
        }
      } else {
        this._parent._delAt(this._posAtParent);
      }
    }
  }
  _at(index) {
    return this._children.get(index);
  }
};
function exists(o) {
  return Boolean(o);
}
function mapNode(node, _) {
  return node.key;
}
function reduceNodes(nodes) {
  return nodes;
}
async function asyncTransformBucket(bucket, asyncMap, asyncReduce) {
  const output = [];
  for (const child of bucket._children.compactArray()) {
    if (child instanceof Bucket) {
      await asyncTransformBucket(child, asyncMap, asyncReduce);
    } else {
      const mappedChildren = await asyncMap(child);
      output.push({
        bitField: bucket._children.bitField(),
        children: mappedChildren
      });
    }
  }
  return asyncReduce(output);
}

// node_modules/hamt-sharding/dist/src/consumable-buffer.js
var START_MASKS = [
  255,
  254,
  252,
  248,
  240,
  224,
  192,
  128
];
var STOP_MASKS = [
  1,
  3,
  7,
  15,
  31,
  63,
  127,
  255
];
var ConsumableBuffer = class {
  constructor(value) {
    __publicField(this, "_value");
    __publicField(this, "_currentBytePos");
    __publicField(this, "_currentBitPos");
    this._value = value;
    this._currentBytePos = value.length - 1;
    this._currentBitPos = 7;
  }
  availableBits() {
    return this._currentBitPos + 1 + this._currentBytePos * 8;
  }
  totalBits() {
    return this._value.length * 8;
  }
  take(bits) {
    let pendingBits = bits;
    let result = 0;
    while (pendingBits > 0 && this._haveBits()) {
      const byte = this._value[this._currentBytePos];
      const availableBits = this._currentBitPos + 1;
      const taking = Math.min(availableBits, pendingBits);
      const value = byteBitsToInt(byte, availableBits - taking, taking);
      result = (result << taking) + value;
      pendingBits -= taking;
      this._currentBitPos -= taking;
      if (this._currentBitPos < 0) {
        this._currentBitPos = 7;
        this._currentBytePos--;
      }
    }
    return result;
  }
  untake(bits) {
    this._currentBitPos += bits;
    while (this._currentBitPos > 7) {
      this._currentBitPos -= 8;
      this._currentBytePos += 1;
    }
  }
  _haveBits() {
    return this._currentBytePos >= 0;
  }
};
function byteBitsToInt(byte, start, length) {
  const mask = maskFor(start, length);
  return (byte & mask) >>> start;
}
function maskFor(start, length) {
  return START_MASKS[start] & STOP_MASKS[Math.min(length + start - 1, 7)];
}

// node_modules/hamt-sharding/dist/src/consumable-hash.js
function wrapHash(hashFn2) {
  function hashing(value) {
    if (value instanceof InfiniteHash) {
      return value;
    } else {
      return new InfiniteHash(value, hashFn2);
    }
  }
  return hashing;
}
var InfiniteHash = class {
  constructor(value, hashFn2) {
    __publicField(this, "_value");
    __publicField(this, "_hashFn");
    __publicField(this, "_depth");
    __publicField(this, "_availableBits");
    __publicField(this, "_currentBufferIndex");
    __publicField(this, "_buffers");
    if (!(value instanceof Uint8Array)) {
      throw new Error("can only hash Uint8Arrays");
    }
    this._value = value;
    this._hashFn = hashFn2;
    this._depth = -1;
    this._availableBits = 0;
    this._currentBufferIndex = 0;
    this._buffers = [];
  }
  async take(bits) {
    let pendingBits = bits;
    while (this._availableBits < pendingBits) {
      await this._produceMoreBits();
    }
    let result = 0;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const available = Math.min(hash.availableBits(), pendingBits);
      const took = hash.take(available);
      result = (result << available) + took;
      pendingBits -= available;
      this._availableBits -= available;
      if (hash.availableBits() === 0) {
        this._currentBufferIndex++;
      }
    }
    return result;
  }
  untake(bits) {
    let pendingBits = bits;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);
      hash.untake(availableForUntake);
      pendingBits -= availableForUntake;
      this._availableBits += availableForUntake;
      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {
        this._depth--;
        this._currentBufferIndex--;
      }
    }
  }
  async _produceMoreBits() {
    this._depth++;
    const value = this._depth > 0 ? concat([this._value, Uint8Array.from([this._depth])]) : this._value;
    const hashValue = await this._hashFn(value);
    const buffer = new ConsumableBuffer(hashValue);
    this._buffers.push(buffer);
    this._availableBits += buffer.availableBits();
  }
};

// node_modules/hamt-sharding/dist/src/index.js
function createHAMT(options) {
  if (options == null || options.hashFn == null) {
    throw new Error("please define an options.hashFn");
  }
  const bucketOptions = {
    bits: options.bits ?? 8,
    hash: wrapHash(options.hashFn)
  };
  return new Bucket(bucketOptions);
}

// node_modules/ipfs-unixfs-importer/dist/src/dir-sharded.js
async function hamtHashFn(buf) {
  return (await murmur3128.encode(buf)).slice(0, 8).reverse();
}
var HAMT_HASH_CODE = BigInt(34);
var DEFAULT_FANOUT_BITS = 8;
var DirSharded = class extends Dir {
  constructor(props, options) {
    super(props, options);
    __publicField(this, "_bucket");
    this._bucket = createHAMT({
      hashFn: hamtHashFn,
      bits: options.shardFanoutBits ?? DEFAULT_FANOUT_BITS
    });
  }
  async put(name, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    await this._bucket.put(name, value);
  }
  async get(name) {
    return this._bucket.get(name);
  }
  childCount() {
    return this._bucket.leafCount();
  }
  directChildrenCount() {
    return this._bucket.childrenCount();
  }
  onlyChild() {
    return this._bucket.onlyChild();
  }
  async *eachChildSeries() {
    for await (const { key, value } of this._bucket.eachLeafSeries()) {
      yield {
        key,
        child: value
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = calculateSize(this._bucket, this, this.options);
    return this.nodeSize;
  }
  async *flush(blockstore) {
    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {
      yield {
        ...entry,
        path: this.path
      };
    }
  }
};
var dir_sharded_default = DirSharded;
async function* flush(bucket, blockstore, shardRoot, options) {
  const children = bucket._children;
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  const links = [];
  let childrenSize = 0n;
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(padLength, "0");
    if (child instanceof Bucket) {
      let shard;
      for await (const subShard of flush(child, blockstore, null, options)) {
        shard = subShard;
      }
      if (shard == null) {
        throw new Error("Could not flush sharded directory, no subshard found");
      }
      links.push({
        Name: labelPrefix,
        Tsize: Number(shard.size),
        Hash: shard.cid
      });
      childrenSize += shard.size;
    } else if (isDir(child.value)) {
      const dir2 = child.value;
      let flushedDir;
      for await (const entry of dir2.flush(blockstore)) {
        flushedDir = entry;
        yield flushedDir;
      }
      if (flushedDir == null) {
        throw new Error("Did not flush dir");
      }
      const label = labelPrefix + child.key;
      links.push({
        Name: label,
        Tsize: Number(flushedDir.size),
        Hash: flushedDir.cid
      });
      childrenSize += flushedDir.size;
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size2 = value.size;
      links.push({
        Name: label,
        Tsize: Number(size2),
        Hash: value.cid
      });
      childrenSize += BigInt(size2 ?? 0);
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: HAMT_HASH_CODE,
    mtime: shardRoot == null ? void 0 : shardRoot.mtime,
    mode: shardRoot == null ? void 0 : shardRoot.mode
  });
  const node = {
    Data: dir.marshal(),
    Links: links
  };
  const buffer = encode(prepare(node));
  const cid = await persist(buffer, blockstore, options);
  const size = BigInt(buffer.byteLength) + childrenSize;
  yield {
    cid,
    unixfs: dir,
    size
  };
}
function isDir(obj) {
  return typeof obj.flush === "function";
}
function calculateSize(bucket, shardRoot, options) {
  const children = bucket._children;
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  const links = [];
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(padLength, "0");
    if (child instanceof Bucket) {
      const size = calculateSize(child, null, options);
      links.push({
        Name: labelPrefix,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V0 : CID_V1
      });
    } else if (typeof child.value.flush === "function") {
      const dir2 = child.value;
      const size = dir2.nodeSize();
      links.push({
        Name: labelPrefix + child.key,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V0 : CID_V1
      });
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size = value.size;
      links.push({
        Name: label,
        Tsize: Number(size),
        Hash: value.cid
      });
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: HAMT_HASH_CODE,
    mtime: shardRoot == null ? void 0 : shardRoot.mtime,
    mode: shardRoot == null ? void 0 : shardRoot.mode
  });
  const buffer = encode(prepare({
    Data: dir.marshal(),
    Links: links
  }));
  return buffer.length;
}

// node_modules/ipfs-unixfs-importer/dist/src/flat-to-shard.js
async function flatToShard(child, dir, threshold, options) {
  let newDir = dir;
  if (dir instanceof DirFlat && dir.estimateNodeSize() > threshold) {
    newDir = await convertToShard(dir, options);
  }
  const parent = newDir.parent;
  if (parent != null) {
    if (newDir !== dir) {
      if (child != null) {
        child.parent = newDir;
      }
      if (newDir.parentKey == null) {
        throw new Error("No parent key found");
      }
      await parent.put(newDir.parentKey, newDir);
    }
    return flatToShard(newDir, parent, threshold, options);
  }
  return newDir;
}
async function convertToShard(oldDir, options) {
  const newDir = new dir_sharded_default({
    root: oldDir.root,
    dir: true,
    parent: oldDir.parent,
    parentKey: oldDir.parentKey,
    path: oldDir.path,
    dirty: oldDir.dirty,
    flat: false,
    mtime: oldDir.mtime,
    mode: oldDir.mode
  }, options);
  for await (const { key, child } of oldDir.eachChildSeries()) {
    await newDir.put(key, child);
  }
  return newDir;
}

// node_modules/ipfs-unixfs-importer/dist/src/utils/to-path-components.js
var toPathComponents = (path = "") => {
  return path.split(new RegExp("(?<!\\\\)\\/")).filter(Boolean);
};

// node_modules/ipfs-unixfs-importer/dist/src/tree-builder.js
async function addToTree(elem, tree, options) {
  var _a, _b;
  const pathElems = toPathComponents(elem.path ?? "");
  const lastIndex = pathElems.length - 1;
  let parent = tree;
  let currentPath = "";
  for (let i = 0; i < pathElems.length; i++) {
    const pathElem = pathElems[i];
    currentPath += `${currentPath !== "" ? "/" : ""}${pathElem}`;
    const last2 = i === lastIndex;
    parent.dirty = true;
    parent.cid = void 0;
    parent.size = void 0;
    if (last2) {
      await parent.put(pathElem, elem);
      tree = await flatToShard(null, parent, options.shardSplitThresholdBytes, options);
    } else {
      let dir = await parent.get(pathElem);
      if (dir == null || !(dir instanceof Dir)) {
        dir = new DirFlat({
          root: false,
          dir: true,
          parent,
          parentKey: pathElem,
          path: currentPath,
          dirty: true,
          flat: true,
          mtime: (_a = dir == null ? void 0 : dir.unixfs) == null ? void 0 : _a.mtime,
          mode: (_b = dir == null ? void 0 : dir.unixfs) == null ? void 0 : _b.mode
        }, options);
      }
      await parent.put(pathElem, dir);
      parent = dir;
    }
  }
  return tree;
}
async function* flushAndYield(tree, blockstore) {
  var _a;
  if (!(tree instanceof Dir)) {
    if (((_a = tree.unixfs) == null ? void 0 : _a.isDirectory()) === true) {
      yield tree;
    }
    return;
  }
  yield* tree.flush(blockstore);
}
function defaultTreeBuilder(options) {
  return async function* treeBuilder(source, block) {
    var _a;
    let tree = new DirFlat({
      root: true,
      dir: true,
      path: "",
      dirty: true,
      flat: true
    }, options);
    let rootDir;
    let singleRoot = false;
    for await (const entry of source) {
      if (entry == null) {
        continue;
      }
      const dir = `${entry.originalPath ?? ""}`.split("/")[0];
      if (dir != null && dir !== "") {
        if (rootDir == null) {
          rootDir = dir;
          singleRoot = true;
        } else if (rootDir !== dir) {
          singleRoot = false;
        }
      }
      tree = await addToTree(entry, tree, options);
      if (((_a = entry.unixfs) == null ? void 0 : _a.isDirectory()) !== true) {
        yield entry;
      }
    }
    if (options.wrapWithDirectory || singleRoot && tree.childCount() > 1) {
      yield* flushAndYield(tree, block);
    } else {
      for await (const unwrapped of tree.eachChildSeries()) {
        if (unwrapped == null) {
          continue;
        }
        yield* flushAndYield(unwrapped.child, block);
      }
    }
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/index.js
async function* importer(source, blockstore, options = {}) {
  let candidates;
  if (Symbol.asyncIterator in source || Symbol.iterator in source) {
    candidates = source;
  } else {
    candidates = [source];
  }
  const wrapWithDirectory = options.wrapWithDirectory ?? false;
  const shardSplitThresholdBytes = options.shardSplitThresholdBytes ?? 262144;
  const shardFanoutBits = options.shardFanoutBits ?? 8;
  const cidVersion = options.cidVersion ?? 1;
  const rawLeaves = options.rawLeaves ?? true;
  const leafType = options.leafType ?? "file";
  const fileImportConcurrency = options.fileImportConcurrency ?? 50;
  const blockWriteConcurrency = options.blockWriteConcurrency ?? 10;
  const reduceSingleLeafToSelf = options.reduceSingleLeafToSelf ?? true;
  const chunker = options.chunker ?? fixedSize();
  const chunkValidator = options.chunkValidator ?? defaultChunkValidator();
  const buildDag = options.dagBuilder ?? defaultDagBuilder({
    chunker,
    chunkValidator,
    wrapWithDirectory,
    layout: options.layout ?? balanced(),
    bufferImporter: options.bufferImporter ?? defaultBufferImporter({
      cidVersion,
      rawLeaves,
      leafType,
      onProgress: options.onProgress
    }),
    blockWriteConcurrency,
    reduceSingleLeafToSelf,
    cidVersion,
    onProgress: options.onProgress
  });
  const buildTree = options.treeBuilder ?? defaultTreeBuilder({
    wrapWithDirectory,
    shardSplitThresholdBytes,
    shardFanoutBits,
    cidVersion,
    onProgress: options.onProgress
  });
  for await (const entry of buildTree(parallelBatch(buildDag(candidates, blockstore), fileImportConcurrency), blockstore)) {
    yield {
      cid: entry.cid,
      path: entry.path,
      unixfs: entry.unixfs,
      size: entry.size
    };
  }
}
async function importFile(content, blockstore, options = {}) {
  const result = await src_default(importer([content], blockstore, options));
  if (result == null) {
    throw new InvalidParametersError("Nothing imported");
  }
  return result;
}
async function importDirectory(content, blockstore, options = {}) {
  const result = await src_default(importer([content], blockstore, options));
  if (result == null) {
    throw new InvalidParametersError("Nothing imported");
  }
  return result;
}
async function importBytes(buf, blockstore, options = {}) {
  return importFile({
    content: buf
  }, blockstore, options);
}
async function importByteStream(bufs, blockstore, options = {}) {
  return importFile({
    content: bufs
  }, blockstore, options);
}

// node_modules/ipfs-unixfs-importer/dist/src/chunker/rabin.js
var import_rabin_wasm = __toESM(require_src(), 1);

// node_modules/@helia/unixfs/dist/src/commands/add.js
var defaultImporterSettings = {
  cidVersion: 1,
  rawLeaves: true,
  layout: balanced({
    maxChildrenPerNode: 1024
  }),
  chunker: fixedSize({
    chunkSize: 1048576
  })
};
async function* addAll(source, blockstore, options = {}) {
  yield* importer(source, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
}
async function addBytes(bytes, blockstore, options = {}) {
  const { cid } = await importBytes(bytes, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}
async function addByteStream(bytes, blockstore, options = {}) {
  const { cid } = await importByteStream(bytes, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}
async function addFile(file, blockstore, options = {}) {
  const { cid } = await importFile(file, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}
async function addDirectory(dir, blockstore, options = {}) {
  const { cid } = await importDirectory({
    ...dir,
    path: dir.path ?? "-"
  }, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}

// node_modules/it-last/dist/src/index.js
function isAsyncIterable3(thing) {
  return thing[Symbol.asyncIterator] != null;
}
function last(source) {
  if (isAsyncIterable3(source)) {
    return (async () => {
      let res2;
      for await (const entry of source) {
        res2 = entry;
      }
      return res2;
    })();
  }
  let res;
  for (const entry of source) {
    res = entry;
  }
  return res;
}
var src_default6 = last;

// node_modules/ipfs-unixfs-exporter/dist/src/errors.js
var _BadPathError = class _BadPathError extends Error {
  constructor(message2 = "Bad path") {
    super(message2);
    __publicField(this, "name", _BadPathError.name);
    __publicField(this, "code", _BadPathError.code);
  }
};
__publicField(_BadPathError, "name", "BadPathError");
__publicField(_BadPathError, "code", "ERR_BAD_PATH");
var BadPathError = _BadPathError;
var _NotFoundError = class _NotFoundError extends Error {
  constructor(message2 = "Not found") {
    super(message2);
    __publicField(this, "name", _NotFoundError.name);
    __publicField(this, "code", _NotFoundError.code);
  }
};
__publicField(_NotFoundError, "name", "NotFoundError");
__publicField(_NotFoundError, "code", "ERR_NOT_FOUND");
var NotFoundError = _NotFoundError;
var _NoResolverError = class _NoResolverError extends Error {
  constructor(message2 = "No resolver") {
    super(message2);
    __publicField(this, "name", _NoResolverError.name);
    __publicField(this, "code", _NoResolverError.code);
  }
};
__publicField(_NoResolverError, "name", "NoResolverError");
__publicField(_NoResolverError, "code", "ERR_NO_RESOLVER");
var NoResolverError = _NoResolverError;
var _NotUnixFSError = class _NotUnixFSError extends Error {
  constructor(message2 = "Not UnixFS") {
    super(message2);
    __publicField(this, "name", _NotUnixFSError.name);
    __publicField(this, "code", _NotUnixFSError.code);
  }
};
__publicField(_NotUnixFSError, "name", "NotUnixFSError");
__publicField(_NotUnixFSError, "code", "ERR_NOT_UNIXFS");
var NotUnixFSError = _NotUnixFSError;
var _OverReadError = class _OverReadError extends Error {
  constructor(message2 = "Over read") {
    super(message2);
    __publicField(this, "name", _OverReadError.name);
    __publicField(this, "code", _OverReadError.code);
  }
};
__publicField(_OverReadError, "name", "OverReadError");
__publicField(_OverReadError, "code", "ERR_OVER_READ");
var OverReadError = _OverReadError;
var _UnderReadError = class _UnderReadError extends Error {
  constructor(message2 = "Under read") {
    super(message2);
    __publicField(this, "name", _UnderReadError.name);
    __publicField(this, "code", _UnderReadError.code);
  }
};
__publicField(_UnderReadError, "name", "UnderReadError");
__publicField(_UnderReadError, "code", "ERR_UNDER_READ");
var UnderReadError = _UnderReadError;
var _NoPropError = class _NoPropError extends Error {
  constructor(message2 = "No Property found") {
    super(message2);
    __publicField(this, "name", _NoPropError.name);
    __publicField(this, "code", _NoPropError.code);
  }
};
__publicField(_NoPropError, "name", "NoPropError");
__publicField(_NoPropError, "code", "ERR_NO_PROP");
var NoPropError = _NoPropError;
var _InvalidParametersError2 = class _InvalidParametersError2 extends Error {
  constructor(message2 = "Invalid parameters") {
    super(message2);
    __publicField(this, "name", _InvalidParametersError2.name);
    __publicField(this, "code", _InvalidParametersError2.code);
  }
};
__publicField(_InvalidParametersError2, "name", "InvalidParametersError");
__publicField(_InvalidParametersError2, "code", "ERR_INVALID_PARAMS");
var InvalidParametersError2 = _InvalidParametersError2;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/resolve-object-path.js
function resolveObjectPath(object, block, cid, name, path, toResolve, depth) {
  let subObject = object;
  let subPath = path;
  while (toResolve.length > 0) {
    const prop = toResolve[0];
    if (prop in subObject) {
      toResolve.shift();
      subPath = `${subPath}/${prop}`;
      const subObjectCid = CID.asCID(subObject[prop]);
      if (subObjectCid != null) {
        return {
          entry: {
            type: "object",
            name,
            path,
            cid,
            node: block,
            depth,
            size: BigInt(block.length),
            content: async function* () {
              yield object;
            }
          },
          next: {
            cid: subObjectCid,
            name: prop,
            path: subPath,
            toResolve
          }
        };
      }
      subObject = subObject[prop];
    } else {
      throw new NoPropError(`No property named ${prop} found in node ${cid}`);
    }
  }
  return {
    entry: {
      type: "object",
      name,
      path,
      cid,
      node: block,
      depth,
      size: BigInt(block.length),
      content: async function* () {
        yield object;
      }
    }
  };
}

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-cbor.js
var resolve = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode4(block);
  return resolveObjectPath(object, block, cid, name, path, toResolve, depth);
};
var dag_cbor_default = resolve;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-json.js
var resolve2 = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode5(block);
  return resolveObjectPath(object, block, cid, name, path, toResolve, depth);
};
var dag_json_default = resolve2;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/extract-data-from-block.js
function extractDataFromBlock(block, blockStart, requestedStart, requestedEnd) {
  const blockLength = BigInt(block.length);
  const blockEnd = BigInt(blockStart + blockLength);
  if (requestedStart >= blockEnd || requestedEnd < blockStart) {
    return new Uint8Array(0);
  }
  if (requestedEnd >= blockStart && requestedEnd < blockEnd) {
    block = block.subarray(0, Number(requestedEnd - blockStart));
  }
  if (requestedStart >= blockStart && requestedStart < blockEnd) {
    block = block.subarray(Number(requestedStart - blockStart));
  }
  return block;
}
var extract_data_from_block_default = extractDataFromBlock;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/validate-offset-and-length.js
var validateOffsetAndLength = (size, offset = 0, length = size) => {
  const fileSize = BigInt(size);
  const start = BigInt(offset ?? 0);
  let end = BigInt(length);
  if (end !== fileSize) {
    end = start + end;
  }
  if (end > fileSize) {
    end = fileSize;
  }
  if (start < 0n) {
    throw new InvalidParametersError2("Offset must be greater than or equal to 0");
  }
  if (start > fileSize) {
    throw new InvalidParametersError2("Offset must be less than the file size");
  }
  if (end < 0n) {
    throw new InvalidParametersError2("Length must be greater than or equal to 0");
  }
  if (end > fileSize) {
    throw new InvalidParametersError2("Length must be less than the file size");
  }
  return {
    start,
    end
  };
};
var validate_offset_and_length_default = validateOffsetAndLength;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/identity.js
var rawContent = (node) => {
  async function* contentGenerator(options = {}) {
    var _a;
    const { start, end } = validate_offset_and_length_default(node.length, options.offset, options.length);
    const buf = extract_data_from_block_default(node, 0n, start, end);
    (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:progress:identity", {
      bytesRead: BigInt(buf.byteLength),
      totalBytes: end - start,
      fileSize: BigInt(node.byteLength)
    }));
    yield buf;
  }
  return contentGenerator;
};
var resolve3 = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  if (toResolve.length > 0) {
    throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);
  }
  const buf = decode(cid.multihash.bytes);
  return {
    entry: {
      type: "identity",
      name,
      path,
      cid,
      content: rawContent(buf.digest),
      depth,
      size: BigInt(buf.digest.length),
      node: buf.digest
    }
  };
};
var identity_default = resolve3;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/json.js
var resolve4 = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode2(block);
  return resolveObjectPath(object, block, cid, name, path, toResolve, depth);
};
var json_default = resolve4;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/raw.js
var rawContent2 = (node) => {
  async function* contentGenerator(options = {}) {
    var _a;
    const { start, end } = validate_offset_and_length_default(node.length, options.offset, options.length);
    const buf = extract_data_from_block_default(node, 0n, start, end);
    (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:progress:raw", {
      bytesRead: BigInt(buf.byteLength),
      totalBytes: end - start,
      fileSize: BigInt(node.byteLength)
    }));
    yield buf;
  }
  return contentGenerator;
};
var resolve5 = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  if (toResolve.length > 0) {
    throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);
  }
  const block = await blockstore.get(cid, options);
  return {
    entry: {
      type: "raw",
      name,
      path,
      cid,
      content: rawContent2(block),
      depth,
      size: BigInt(block.length),
      node: block
    }
  };
};
var raw_default = resolve5;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/find-cid-in-shard.js
var hashFn = async function(buf) {
  return (await murmur3128.encode(buf)).slice(0, 8).reverse();
};
var addLinksToHamtBucket = async (links, bucket, rootBucket) => {
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  await Promise.all(links.map(async (link) => {
    if (link.Name == null) {
      throw new Error("Unexpected Link without a Name");
    }
    if (link.Name.length === padLength) {
      const pos = parseInt(link.Name, 16);
      bucket._putObjectAt(pos, new Bucket({
        hash: rootBucket._options.hash,
        bits: rootBucket._options.bits
      }, bucket, pos));
      return;
    }
    await rootBucket.put(link.Name.substring(2), true);
  }));
};
var toPrefix = (position, padLength) => {
  return position.toString(16).toUpperCase().padStart(padLength, "0").substring(0, padLength);
};
var toBucketPath = (position) => {
  let bucket = position.bucket;
  const path = [];
  while (bucket._parent != null) {
    path.push(bucket);
    bucket = bucket._parent;
  }
  path.push(bucket);
  return path.reverse();
};
var findShardCid = async (node, name, blockstore, context, options) => {
  if (context == null) {
    if (node.Data == null) {
      throw new NotUnixFSError("no data in PBNode");
    }
    let dir;
    try {
      dir = UnixFS.unmarshal(node.Data);
    } catch (err) {
      throw new NotUnixFSError(err.message);
    }
    if (dir.type !== "hamt-sharded-directory") {
      throw new NotUnixFSError("not a HAMT");
    }
    if (dir.fanout == null) {
      throw new NotUnixFSError("missing fanout");
    }
    const rootBucket = createHAMT({
      hashFn,
      bits: Math.log2(Number(dir.fanout))
    });
    context = {
      rootBucket,
      hamtDepth: 1,
      lastBucket: rootBucket
    };
  }
  const padLength = (context.lastBucket.tableSize() - 1).toString(16).length;
  await addLinksToHamtBucket(node.Links, context.lastBucket, context.rootBucket);
  const position = await context.rootBucket._findNewBucketAndPos(name);
  let prefix = toPrefix(position.pos, padLength);
  const bucketPath = toBucketPath(position);
  if (bucketPath.length > context.hamtDepth) {
    context.lastBucket = bucketPath[context.hamtDepth];
    prefix = toPrefix(context.lastBucket._posAtParent, padLength);
  }
  const link = node.Links.find((link2) => {
    if (link2.Name == null) {
      return false;
    }
    const entryPrefix = link2.Name.substring(0, padLength);
    const entryName = link2.Name.substring(padLength);
    if (entryPrefix !== prefix) {
      return false;
    }
    if (entryName !== "" && entryName !== name) {
      return false;
    }
    return true;
  });
  if (link == null) {
    return;
  }
  if (link.Name != null && link.Name.substring(padLength) === name) {
    return link.Hash;
  }
  context.hamtDepth++;
  const block = await blockstore.get(link.Hash, options);
  node = decode3(block);
  return findShardCid(node, name, blockstore, context, options);
};
var find_cid_in_shard_default = findShardCid;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/directory.js
var directoryContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  async function* yieldDirectoryContent(options = {}) {
    var _a;
    const offset = options.offset ?? 0;
    const length = options.length ?? node.Links.length;
    const links = node.Links.slice(offset, length);
    (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:walk:directory", {
      cid
    }));
    yield* pipe(links, (source) => src_default4(source, (link) => {
      return async () => {
        const linkName = link.Name ?? "";
        const linkPath = `${path}/${linkName}`;
        const result = await resolve8(link.Hash, linkName, linkPath, [], depth + 1, blockstore, options);
        return result.entry;
      };
    }), (source) => parallel(source, {
      ordered: true,
      concurrency: options.blockReadConcurrency
    }), (source) => src_default3(source, (entry) => entry != null));
  }
  return yieldDirectoryContent;
};
var directory_default = directoryContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/file.js
async function walkDAG(blockstore, node, queue, streamPosition, start, end, options) {
  if (node instanceof Uint8Array) {
    const buf = extract_data_from_block_default(node, streamPosition, start, end);
    queue.push(buf);
    return;
  }
  if (node.Data == null) {
    throw new NotUnixFSError("no data in PBNode");
  }
  let file;
  try {
    file = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError(err.message);
  }
  if (file.data != null) {
    const data = file.data;
    const buf = extract_data_from_block_default(data, streamPosition, start, end);
    queue.push(buf);
    streamPosition += BigInt(buf.byteLength);
  }
  const childOps = [];
  if (node.Links.length !== file.blockSizes.length) {
    throw new NotUnixFSError("Inconsistent block sizes and dag links");
  }
  for (let i = 0; i < node.Links.length; i++) {
    const childLink = node.Links[i];
    const childStart = streamPosition;
    const childEnd = childStart + file.blockSizes[i];
    if (start >= childStart && start < childEnd || // child has offset byte
    end >= childStart && end <= childEnd || // child has end byte
    start < childStart && end > childEnd) {
      childOps.push({
        link: childLink,
        blockStart: streamPosition
      });
    }
    streamPosition = childEnd;
    if (streamPosition > end) {
      break;
    }
  }
  await pipe(childOps, (source) => src_default4(source, (op) => {
    return async () => {
      const block = await blockstore.get(op.link.Hash, options);
      return {
        ...op,
        block
      };
    };
  }), (source) => parallel(source, {
    ordered: true,
    concurrency: options.blockReadConcurrency
  }), async (source) => {
    for await (const { link, block, blockStart } of source) {
      let child;
      switch (link.Hash.code) {
        case code3:
          child = decode3(block);
          break;
        case code2:
          child = block;
          break;
        default:
          queue.end(new NotUnixFSError(`Unsupported codec: ${link.Hash.code}`));
          return;
      }
      const childQueue = new PQueue({
        concurrency: 1
      });
      childQueue.on("error", (error) => {
        queue.end(error);
      });
      void childQueue.add(async () => {
        var _a;
        (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:walk:file", {
          cid: link.Hash
        }));
        await walkDAG(blockstore, child, queue, blockStart, start, end, options);
      });
      await childQueue.onIdle();
    }
  });
  if (streamPosition >= end) {
    queue.end();
  }
}
var fileContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  async function* yieldFileContent(options = {}) {
    var _a, _b;
    const fileSize = unixfs2.fileSize();
    if (fileSize === void 0) {
      throw new Error("File was a directory");
    }
    const { start, end } = validate_offset_and_length_default(fileSize, options.offset, options.length);
    if (end === 0n) {
      return;
    }
    let read = 0n;
    const wanted = end - start;
    const queue = pushable();
    (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:walk:file", {
      cid
    }));
    void walkDAG(blockstore, node, queue, 0n, start, end, options).catch((err) => {
      queue.end(err);
    });
    for await (const buf of queue) {
      if (buf == null) {
        continue;
      }
      read += BigInt(buf.byteLength);
      if (read > wanted) {
        queue.end();
        throw new OverReadError("Read too many bytes - the file size reported by the UnixFS data in the root node may be incorrect");
      }
      if (read === wanted) {
        queue.end();
      }
      (_b = options.onProgress) == null ? void 0 : _b.call(options, new CustomProgressEvent("unixfs:exporter:progress:unixfs:file", {
        bytesRead: read,
        totalBytes: wanted,
        fileSize
      }));
      yield buf;
    }
    if (read < wanted) {
      throw new UnderReadError("Traversed entire DAG but did not read enough bytes");
    }
  }
  return yieldFileContent;
};
var file_default = fileContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js
var hamtShardedDirectoryContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  function yieldHamtDirectoryContent(options = {}) {
    var _a;
    (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:walk:hamt-sharded-directory", {
      cid
    }));
    return listDirectory(node, path, resolve8, depth, blockstore, options);
  }
  return yieldHamtDirectoryContent;
};
async function* listDirectory(node, path, resolve8, depth, blockstore, options) {
  const links = node.Links;
  if (node.Data == null) {
    throw new NotUnixFSError("no data in PBNode");
  }
  let dir;
  try {
    dir = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError(err.message);
  }
  if (dir.fanout == null) {
    throw new NotUnixFSError("missing fanout");
  }
  const padLength = (dir.fanout - 1n).toString(16).length;
  const results = pipe(links, (source) => src_default4(source, (link) => {
    return async () => {
      var _a;
      const name = link.Name != null ? link.Name.substring(padLength) : null;
      if (name != null && name !== "") {
        const result = await resolve8(link.Hash, name, `${path}/${name}`, [], depth + 1, blockstore, options);
        return { entries: result.entry == null ? [] : [result.entry] };
      } else {
        const block = await blockstore.get(link.Hash, options);
        node = decode3(block);
        (_a = options.onProgress) == null ? void 0 : _a.call(options, new CustomProgressEvent("unixfs:exporter:walk:hamt-sharded-directory", {
          cid: link.Hash
        }));
        return { entries: listDirectory(node, path, resolve8, depth, blockstore, options) };
      }
    };
  }), (source) => parallel(source, {
    ordered: true,
    concurrency: options.blockReadConcurrency
  }));
  for await (const { entries } of results) {
    yield* entries;
  }
}
var hamt_sharded_directory_default = hamtShardedDirectoryContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/index.js
var findLinkCid = (node, name) => {
  const link = node.Links.find((link2) => link2.Name === name);
  return link == null ? void 0 : link.Hash;
};
var contentExporters = {
  raw: file_default,
  file: file_default,
  directory: directory_default,
  "hamt-sharded-directory": hamt_sharded_directory_default,
  metadata: (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
    return () => [];
  },
  symlink: (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
    return () => [];
  }
};
var unixFsResolver = async (cid, name, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const node = decode3(block);
  let unixfs2;
  let next;
  if (name == null) {
    name = cid.toString();
  }
  if (node.Data == null) {
    throw new NotUnixFSError("no data in PBNode");
  }
  try {
    unixfs2 = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError(err.message);
  }
  if (path == null) {
    path = name;
  }
  if (toResolve.length > 0) {
    let linkCid;
    if ((unixfs2 == null ? void 0 : unixfs2.type) === "hamt-sharded-directory") {
      linkCid = await find_cid_in_shard_default(node, toResolve[0], blockstore);
    } else {
      linkCid = findLinkCid(node, toResolve[0]);
    }
    if (linkCid == null) {
      throw new NotFoundError("file does not exist");
    }
    const nextName = toResolve.shift();
    const nextPath = `${path}/${nextName}`;
    next = {
      cid: linkCid,
      toResolve,
      name: nextName ?? "",
      path: nextPath
    };
  }
  const content = contentExporters[unixfs2.type](cid, node, unixfs2, path, resolve8, depth, blockstore);
  if (content == null) {
    throw new NotFoundError("could not find content exporter");
  }
  if (unixfs2.isDirectory()) {
    return {
      entry: {
        type: "directory",
        name,
        path,
        cid,
        content,
        unixfs: unixfs2,
        depth,
        node,
        size: unixfs2.fileSize()
      },
      next
    };
  }
  return {
    entry: {
      type: "file",
      name,
      path,
      cid,
      content,
      unixfs: unixfs2,
      depth,
      node,
      size: unixfs2.fileSize()
    },
    next
  };
};
var unixfs_v1_default = unixFsResolver;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/index.js
var resolvers = {
  [code3]: unixfs_v1_default,
  [code2]: raw_default,
  [code4]: dag_cbor_default,
  [code5]: dag_json_default,
  [identity.code]: identity_default,
  [code]: json_default
};
var resolve6 = async (cid, name, path, toResolve, depth, blockstore, options) => {
  const resolver = resolvers[cid.code];
  if (resolver == null) {
    throw new NoResolverError(`No resolver for code ${cid.code}`);
  }
  return resolver(cid, name, path, toResolve, resolve6, depth, blockstore, options);
};
var resolvers_default = resolve6;

// node_modules/ipfs-unixfs-exporter/dist/src/index.js
var toPathComponents2 = (path = "") => {
  return (path.trim().match(/([^\\^/]|\\\/)+/g) ?? []).filter(Boolean);
};
var cidAndRest = (path) => {
  if (path instanceof Uint8Array) {
    return {
      cid: CID.decode(path),
      toResolve: []
    };
  }
  const cid = CID.asCID(path);
  if (cid != null) {
    return {
      cid,
      toResolve: []
    };
  }
  if (typeof path === "string") {
    if (path.indexOf("/ipfs/") === 0) {
      path = path.substring(6);
    }
    const output = toPathComponents2(path);
    return {
      cid: CID.parse(output[0]),
      toResolve: output.slice(1)
    };
  }
  throw new BadPathError(`Unknown path type ${path}`);
};
async function* walkPath(path, blockstore, options = {}) {
  let { cid, toResolve } = cidAndRest(path);
  let name = cid.toString();
  let entryPath = name;
  const startingDepth = toResolve.length;
  while (true) {
    const result = await resolvers_default(cid, name, entryPath, toResolve, startingDepth, blockstore, options);
    if (result.entry == null && result.next == null) {
      throw new NotFoundError(`Could not resolve ${path}`);
    }
    if (result.entry != null) {
      yield result.entry;
    }
    if (result.next == null) {
      return;
    }
    toResolve = result.next.toResolve;
    cid = result.next.cid;
    name = result.next.name;
    entryPath = result.next.path;
  }
}
async function exporter(path, blockstore, options = {}) {
  const result = await src_default6(walkPath(path, blockstore, options));
  if (result == null) {
    throw new NotFoundError(`Could not resolve ${path}`);
  }
  return result;
}
async function* recursive(path, blockstore, options = {}) {
  const node = await exporter(path, blockstore, options);
  if (node == null) {
    return;
  }
  yield node;
  if (node.type === "directory") {
    for await (const child of recurse(node, options)) {
      yield child;
    }
  }
  async function* recurse(node2, options2) {
    for await (const file of node2.content(options2)) {
      yield file;
      if (file instanceof Uint8Array) {
        continue;
      }
      if (file.type === "directory") {
        yield* recurse(file, options2);
      }
    }
  }
}

// node_modules/@helia/unixfs/dist/src/errors.js
var UnixFSError = class extends Error {
  constructor(message2, name, code6) {
    super(message2);
    __publicField(this, "name");
    __publicField(this, "code");
    this.name = name;
    this.code = code6;
  }
};
var NotUnixFSError2 = class extends UnixFSError {
  constructor(message2 = "not a Unixfs node") {
    super(message2, "NotUnixFSError", "ERR_NOT_UNIXFS");
  }
};
var InvalidPBNodeError = class extends UnixFSError {
  constructor(message2 = "invalid PBNode") {
    super(message2, "InvalidPBNodeError", "ERR_INVALID_PBNODE");
  }
};
var UnknownError = class extends UnixFSError {
  constructor(message2 = "unknown error") {
    super(message2, "InvalidPBNodeError", "ERR_UNKNOWN_ERROR");
  }
};
var AlreadyExistsError = class extends UnixFSError {
  constructor(message2 = "path already exists") {
    super(message2, "AlreadyExistsError", "ERR_ALREADY_EXISTS");
  }
};
var DoesNotExistError = class extends UnixFSError {
  constructor(message2 = "path does not exist") {
    super(message2, "DoesNotExistError", "ERR_DOES_NOT_EXIST");
  }
};
var NoContentError = class extends UnixFSError {
  constructor(message2 = "no content") {
    super(message2, "NoContentError", "ERR_NO_CONTENT");
  }
};
var NotAFileError = class extends UnixFSError {
  constructor(message2 = "not a file") {
    super(message2, "NotAFileError", "ERR_NOT_A_FILE");
  }
};
var NotADirectoryError = class extends UnixFSError {
  constructor(message2 = "not a directory") {
    super(message2, "NotADirectoryError", "ERR_NOT_A_DIRECTORY");
  }
};
var InvalidParametersError3 = class extends UnixFSError {
  constructor(message2 = "invalid parameters") {
    super(message2, "InvalidParametersError", "ERR_INVALID_PARAMETERS");
  }
};

// node_modules/@helia/unixfs/dist/src/commands/utils/add-link.js
var import_sparse_array3 = __toESM(require_sparse_array(), 1);

// node_modules/@helia/unixfs/dist/src/commands/utils/consumable-hash.js
function wrapHash2(hashFn2) {
  function hashing(value) {
    if (value instanceof InfiniteHash2) {
      return value;
    } else {
      return new InfiniteHash2(value, hashFn2);
    }
  }
  return hashing;
}
var InfiniteHash2 = class {
  constructor(value, hashFn2) {
    __publicField(this, "_value");
    __publicField(this, "_hashFn");
    __publicField(this, "_depth");
    __publicField(this, "_availableBits");
    __publicField(this, "_currentBufferIndex");
    __publicField(this, "_buffers");
    if (!(value instanceof Uint8Array)) {
      throw new Error("can only hash Uint8Arrays");
    }
    this._value = value;
    this._hashFn = hashFn2;
    this._depth = -1;
    this._availableBits = 0;
    this._currentBufferIndex = 0;
    this._buffers = [];
  }
  async take(bits) {
    let pendingBits = bits;
    while (this._availableBits < pendingBits) {
      await this._produceMoreBits();
    }
    let result = 0;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const available = Math.min(hash.availableBits(), pendingBits);
      const took = hash.take(available);
      result = (result << available) + took;
      pendingBits -= available;
      this._availableBits -= available;
      if (hash.availableBits() === 0) {
        this._currentBufferIndex++;
      }
    }
    return result;
  }
  untake(bits) {
    let pendingBits = bits;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);
      hash.untake(availableForUntake);
      pendingBits -= availableForUntake;
      this._availableBits += availableForUntake;
      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {
        this._depth--;
        this._currentBufferIndex--;
      }
    }
  }
  async _produceMoreBits() {
    this._depth++;
    const value = this._depth > 0 ? concat([this._value, Uint8Array.from([this._depth])]) : this._value;
    const hashValue = await this._hashFn(value);
    const buffer = new ConsumableBuffer2(hashValue);
    this._buffers.push(buffer);
    this._availableBits += buffer.availableBits();
  }
};
var START_MASKS2 = [
  255,
  254,
  252,
  248,
  240,
  224,
  192,
  128
];
var STOP_MASKS2 = [
  1,
  3,
  7,
  15,
  31,
  63,
  127,
  255
];
var ConsumableBuffer2 = class {
  constructor(value) {
    __publicField(this, "_value");
    __publicField(this, "_currentBytePos");
    __publicField(this, "_currentBitPos");
    this._value = value;
    this._currentBytePos = value.length - 1;
    this._currentBitPos = 7;
  }
  availableBits() {
    return this._currentBitPos + 1 + this._currentBytePos * 8;
  }
  totalBits() {
    return this._value.length * 8;
  }
  take(bits) {
    let pendingBits = bits;
    let result = 0;
    while (pendingBits > 0 && this._haveBits()) {
      const byte = this._value[this._currentBytePos];
      const availableBits = this._currentBitPos + 1;
      const taking = Math.min(availableBits, pendingBits);
      const value = byteBitsToInt2(byte, availableBits - taking, taking);
      result = (result << taking) + value;
      pendingBits -= taking;
      this._currentBitPos -= taking;
      if (this._currentBitPos < 0) {
        this._currentBitPos = 7;
        this._currentBytePos--;
      }
    }
    return result;
  }
  untake(bits) {
    this._currentBitPos += bits;
    while (this._currentBitPos > 7) {
      this._currentBitPos -= 8;
      this._currentBytePos += 1;
    }
  }
  _haveBits() {
    return this._currentBytePos >= 0;
  }
};
function byteBitsToInt2(byte, start, length) {
  const mask = maskFor2(start, length);
  return (byte & mask) >>> start;
}
function maskFor2(start, length) {
  return START_MASKS2[start] & STOP_MASKS2[Math.min(length + start - 1, 7)];
}

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-constants.js
var hamtHashCode = BigInt(murmur3128.code);
var hamtBucketBits = 8;
async function hamtHashFn2(buf) {
  return (await murmur3128.encode(buf)).subarray(0, 8).reverse();
}

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-utils.js
var import_sparse_array2 = __toESM(require_sparse_array(), 1);

// node_modules/@helia/unixfs/dist/src/commands/utils/persist.js
var persist2 = async (buffer, blockstore, options) => {
  if (options.codec == null) {
    options.codec = src_exports;
  }
  const multihash = await sha256.digest(buffer);
  const cid = CID.create(options.cidVersion, options.codec.code, multihash);
  await blockstore.put(cid, buffer, {
    ...options,
    signal: options.signal
  });
  return cid;
};

// node_modules/@helia/unixfs/dist/src/commands/utils/dir-sharded.js
var Dir2 = class {
  constructor(props, options) {
    __publicField(this, "options");
    __publicField(this, "root");
    __publicField(this, "dir");
    __publicField(this, "path");
    __publicField(this, "dirty");
    __publicField(this, "flat");
    __publicField(this, "parent");
    __publicField(this, "parentKey");
    __publicField(this, "unixfs");
    __publicField(this, "mode");
    __publicField(this, "mtime");
    __publicField(this, "cid");
    __publicField(this, "size");
    __publicField(this, "nodeSize");
    this.options = options ?? {};
    this.root = props.root;
    this.dir = props.dir;
    this.path = props.path;
    this.dirty = props.dirty;
    this.flat = props.flat;
    this.parent = props.parent;
    this.parentKey = props.parentKey;
    this.unixfs = props.unixfs;
    this.mode = props.mode;
    this.mtime = props.mtime;
  }
};
var DirSharded2 = class extends Dir2 {
  constructor(props, options) {
    super(props, options);
    __publicField(this, "_bucket");
    this._bucket = createHAMT({
      hashFn: hamtHashFn2,
      bits: 8
    });
  }
  async put(name, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    await this._bucket.put(name, value);
  }
  async get(name) {
    return this._bucket.get(name);
  }
  childCount() {
    return this._bucket.leafCount();
  }
  directChildrenCount() {
    return this._bucket.childrenCount();
  }
  onlyChild() {
    return this._bucket.onlyChild();
  }
  async *eachChildSeries() {
    for await (const { key, value } of this._bucket.eachLeafSeries()) {
      yield {
        key,
        child: value
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = calculateSize2(this._bucket, this, this.options);
    return this.nodeSize;
  }
  async *flush(blockstore) {
    for await (const entry of flush2(this._bucket, blockstore, this, this.options)) {
      yield {
        ...entry,
        path: this.path
      };
    }
  }
};
async function* flush2(bucket, blockstore, shardRoot, options) {
  const children = bucket._children;
  const links = [];
  let childrenSize = 0n;
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(2, "0");
    if (child instanceof Bucket) {
      let shard;
      for await (const subShard of flush2(child, blockstore, null, options)) {
        shard = subShard;
      }
      if (shard == null) {
        throw new Error("Could not flush sharded directory, no subshard found");
      }
      links.push({
        Name: labelPrefix,
        Tsize: Number(shard.size),
        Hash: shard.cid
      });
      childrenSize += shard.size;
    } else if (isDir2(child.value)) {
      const dir2 = child.value;
      let flushedDir;
      for await (const entry of dir2.flush(blockstore)) {
        flushedDir = entry;
        yield flushedDir;
      }
      if (flushedDir == null) {
        throw new Error("Did not flush dir");
      }
      const label = labelPrefix + child.key;
      links.push({
        Name: label,
        Tsize: Number(flushedDir.size),
        Hash: flushedDir.cid
      });
      childrenSize += flushedDir.size;
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size2 = value.size;
      links.push({
        Name: label,
        Tsize: Number(size2),
        Hash: value.cid
      });
      childrenSize += BigInt(size2 ?? 0);
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: hamtHashCode,
    mtime: shardRoot == null ? void 0 : shardRoot.mtime,
    mode: shardRoot == null ? void 0 : shardRoot.mode
  });
  const node = {
    Data: dir.marshal(),
    Links: links
  };
  const buffer = encode(prepare(node));
  const cid = await persist2(buffer, blockstore, options);
  const size = BigInt(buffer.byteLength) + childrenSize;
  yield {
    cid,
    unixfs: dir,
    size
  };
}
function isDir2(obj) {
  return typeof obj.flush === "function";
}
function calculateSize2(bucket, shardRoot, options) {
  const children = bucket._children;
  const links = [];
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(2, "0");
    if (child instanceof Bucket) {
      const size = calculateSize2(child, null, options);
      links.push({
        Name: labelPrefix,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V02 : CID_V12
      });
    } else if (typeof child.value.flush === "function") {
      const dir2 = child.value;
      const size = dir2.nodeSize();
      links.push({
        Name: labelPrefix + child.key,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V02 : CID_V12
      });
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size = value.size;
      links.push({
        Name: label,
        Tsize: Number(size),
        Hash: value.cid
      });
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: hamtHashCode,
    mtime: shardRoot == null ? void 0 : shardRoot.mtime,
    mode: shardRoot == null ? void 0 : shardRoot.mode
  });
  const buffer = encode(prepare({
    Data: dir.marshal(),
    Links: links
  }));
  return buffer.length;
}
var CID_V02 = CID.parse("QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn");
var CID_V12 = CID.parse("zdj7WbTaiJT1fgatdet9Ei9iDB5hdCxkbVyhyh8YTUnXMiwYi");

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-utils.js
var log = logger("helia:unixfs:commands:utils:hamt-utils");
var toPrefix2 = (position) => {
  return position.toString(16).toUpperCase().padStart(2, "0").substring(0, 2);
};
var createShard = async (blockstore, contents, options) => {
  const shard = new DirSharded2({
    root: true,
    dir: true,
    parent: void 0,
    parentKey: void 0,
    path: "",
    dirty: true,
    flat: false,
    mtime: options.mtime,
    mode: options.mode
  }, options);
  for (let i = 0; i < contents.length; i++) {
    await shard._bucket.put(contents[i].name, {
      size: contents[i].size,
      cid: contents[i].cid
    });
  }
  const res = await src_default6(shard.flush(blockstore));
  if (res == null) {
    throw new Error("Flushing shard yielded no result");
  }
  return res;
};
var updateShardedDirectory = async (path, blockstore, options) => {
  const shardRoot = UnixFS.unmarshal(path[0].node.Data ?? new Uint8Array(0));
  const fanout = BigInt(Math.pow(2, hamtBucketBits));
  path.reverse();
  let cid;
  let node;
  for (let i = 0; i < path.length; i++) {
    const isRoot = i === path.length - 1;
    const segment = path[i];
    const data = Uint8Array.from(segment.children.bitField().reverse());
    const dir = new UnixFS({
      type: "hamt-sharded-directory",
      data,
      fanout,
      hashType: hamtHashCode
    });
    if (isRoot) {
      dir.mtime = shardRoot.mtime;
      dir.mode = shardRoot.mode;
    }
    node = {
      Data: dir.marshal(),
      Links: segment.node.Links
    };
    const block = encode(prepare(node));
    cid = await persist2(block, blockstore, options);
    if (!isRoot) {
      const nextSegment = path[i + 1];
      if (nextSegment == null) {
        throw new Error("Was not operating on shard root but also had no parent?");
      }
      log("updating link in parent sub-shard with prefix %s", nextSegment.prefix);
      nextSegment.node.Links = nextSegment.node.Links.filter((l) => l.Name !== nextSegment.prefix);
      nextSegment.node.Links.push({
        Name: nextSegment.prefix,
        Hash: cid,
        Tsize: segment.node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), block.byteLength)
      });
    }
  }
  if (cid == null || node == null) {
    throw new Error("Noting persisted");
  }
  return { cid, node };
};
var recreateShardedDirectory = async (cid, fileName, blockstore, options) => {
  const wrapped = wrapHash2(hamtHashFn2);
  const hash = wrapped(fromString(fileName));
  const path = [];
  while (true) {
    const block = await blockstore.get(cid, options);
    const node = decode3(block);
    const children = new import_sparse_array2.default();
    const index = await hash.take(hamtBucketBits);
    const prefix = toPrefix2(index);
    path.push({
      prefix,
      children,
      node
    });
    let childLink;
    for (const link of node.Links) {
      const linkName2 = link.Name ?? "";
      if (linkName2.length < 2) {
        throw new Error("Invalid HAMT - link name was too short");
      }
      const position = parseInt(linkName2.substring(0, 2), 16);
      children.set(position, true);
      if (linkName2.startsWith(prefix)) {
        childLink = link;
      }
    }
    if (childLink == null) {
      log("no link found with prefix %s for %s", prefix, fileName);
      break;
    }
    const linkName = childLink.Name ?? "";
    if (linkName.length < 2) {
      throw new Error("Invalid HAMT - link name was too short");
    }
    if (linkName.length === 2) {
      cid = childLink.Hash;
      log("descend into sub-shard with prefix %s", linkName);
      continue;
    }
    break;
  }
  return { path, hash };
};

// node_modules/@helia/unixfs/dist/src/commands/utils/is-over-shard-threshold.js
async function isOverShardThreshold(node, blockstore, threshold, options) {
  if (node.Data == null) {
    throw new Error("DagPB node had no data");
  }
  const unixfs2 = UnixFS.unmarshal(node.Data);
  let size;
  if (unixfs2.type === "directory") {
    size = estimateNodeSize(node);
  } else if (unixfs2.type === "hamt-sharded-directory") {
    size = await estimateShardSize(node, 0, threshold, blockstore, options);
  } else {
    throw new Error("Can only estimate the size of directories or shards");
  }
  return size > threshold;
}
function estimateNodeSize(node) {
  let size = 0;
  for (const link of node.Links) {
    size += (link.Name ?? "").length;
    size += link.Hash.version === 1 ? CID_V12.bytes.byteLength : CID_V02.bytes.byteLength;
  }
  return size;
}
async function estimateShardSize(node, current, max, blockstore, options) {
  if (current > max) {
    return max;
  }
  if (node.Data == null) {
    return current;
  }
  const unixfs2 = UnixFS.unmarshal(node.Data);
  if (!unixfs2.isDirectory()) {
    return current;
  }
  for (const link of node.Links) {
    let name = link.Name ?? "";
    name = name.substring(2);
    current += name.length;
    current += link.Hash.bytes.byteLength;
    if (link.Hash.code === code3) {
      const block = await blockstore.get(link.Hash, options);
      const node2 = decode3(block);
      current += await estimateShardSize(node2, current, max, blockstore, options);
    }
  }
  return current;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/add-link.js
var log2 = logger("helia:unixfs:components:utils:add-link");
async function addLink(parent, child, blockstore, options) {
  if (parent.node.Data == null) {
    throw new InvalidParametersError3("Invalid parent passed to addLink");
  }
  const meta = UnixFS.unmarshal(parent.node.Data);
  if (meta.type === "hamt-sharded-directory") {
    log2("adding link to sharded directory");
    return addToShardedDirectory(parent, child, blockstore, options);
  }
  log2(`adding ${child.Name} (${child.Hash}) to regular directory`);
  const result = await addToDirectory(parent, child, blockstore, options);
  if (await isOverShardThreshold(result.node, blockstore, options.shardSplitThresholdBytes, options)) {
    log2("converting directory to sharded directory");
    const converted = await convertToShardedDirectory(result, blockstore);
    result.cid = converted.cid;
    result.node = decode3(await blockstore.get(converted.cid, options));
  }
  return result;
}
var convertToShardedDirectory = async (parent, blockstore) => {
  if (parent.node.Data == null) {
    throw new InvalidParametersError3("Invalid parent passed to convertToShardedDirectory");
  }
  const unixfs2 = UnixFS.unmarshal(parent.node.Data);
  const result = await createShard(blockstore, parent.node.Links.map((link) => ({
    name: link.Name ?? "",
    size: BigInt(link.Tsize ?? 0),
    cid: link.Hash
  })), {
    mode: unixfs2.mode,
    mtime: unixfs2.mtime,
    cidVersion: parent.cid.version
  });
  log2(`converted directory to sharded directory ${result.cid}`);
  return result;
};
var addToDirectory = async (parent, child, blockstore, options) => {
  const parentLinks = parent.node.Links.filter((link) => {
    const matches = link.Name === child.Name;
    if (matches && !options.allowOverwriting) {
      throw new AlreadyExistsError();
    }
    return !matches;
  });
  parentLinks.push(child);
  if (parent.node.Data == null) {
    throw new InvalidPBNodeError("Parent node with no data passed to addToDirectory");
  }
  const node = UnixFS.unmarshal(parent.node.Data);
  let data;
  if (node.mtime != null) {
    const ms = Date.now();
    const secs = Math.floor(ms / 1e3);
    node.mtime = {
      secs: BigInt(secs),
      nsecs: (ms - secs * 1e3) * 1e3
    };
    data = node.marshal();
  } else {
    data = parent.node.Data;
  }
  parent.node = prepare({
    Data: data,
    Links: parentLinks
  });
  const buf = encode(parent.node);
  const hash = await sha256.digest(buf);
  const cid = CID.create(parent.cid.version, code3, hash);
  await blockstore.put(cid, buf);
  return {
    node: parent.node,
    cid
  };
};
var addToShardedDirectory = async (parent, child, blockstore, options) => {
  var _a;
  const { path, hash } = await recreateShardedDirectory(parent.cid, child.Name, blockstore, options);
  const finalSegment = path[path.length - 1];
  if (finalSegment == null) {
    throw new Error("Invalid HAMT, could not generate path");
  }
  const prefix = finalSegment.prefix;
  const index = parseInt(prefix, 16);
  log2("next prefix for %s is %s", child.Name, prefix);
  const linkName = `${prefix}${child.Name}`;
  const existingLink = finalSegment.node.Links.find((l) => (l.Name ?? "").startsWith(prefix));
  if (existingLink != null) {
    log2("link %s was present in shard", linkName);
    if (existingLink.Name === linkName) {
      if (!options.allowOverwriting) {
        throw new AlreadyExistsError();
      }
      log2("overwriting %s in subshard", child.Name);
      finalSegment.node.Links = finalSegment.node.Links.filter((l) => l.Name !== linkName);
      finalSegment.node.Links.push({
        Name: linkName,
        Hash: child.Hash,
        Tsize: child.Tsize
      });
    } else if (((_a = existingLink.Name) == null ? void 0 : _a.length) === 2) {
      throw new Error("Existing link was subshard?!");
    } else {
      log2("prefix %s already exists, creating new subshard", prefix);
      const index2 = finalSegment.node.Links.findIndex((l) => {
        var _a2;
        return (_a2 = l.Name) == null ? void 0 : _a2.startsWith(prefix);
      });
      const sibling = finalSegment.node.Links.splice(index2, 1)[0];
      const siblingName = (sibling.Name ?? "").substring(2);
      const wrapped = wrapHash2(hamtHashFn2);
      const siblingHash = wrapped(fromString(siblingName));
      for (let i = 0; i < path.length; i++) {
        await siblingHash.take(hamtBucketBits);
      }
      while (true) {
        const siblingIndex = await siblingHash.take(hamtBucketBits);
        const siblingPrefix = toPrefix2(siblingIndex);
        sibling.Name = `${siblingPrefix}${siblingName}`;
        const newIndex = await hash.take(hamtBucketBits);
        const newPrefix = toPrefix2(newIndex);
        if (siblingPrefix === newPrefix) {
          const children2 = new import_sparse_array3.default();
          children2.set(newIndex, true);
          path.push({
            prefix: newPrefix,
            children: children2,
            node: {
              Links: []
            }
          });
          continue;
        }
        const children = new import_sparse_array3.default();
        children.set(newIndex, true);
        children.set(siblingIndex, true);
        path.push({
          prefix,
          children,
          node: {
            Links: [
              sibling,
              {
                Name: `${newPrefix}${child.Name}`,
                Hash: child.Hash,
                Tsize: child.Tsize
              }
            ]
          }
        });
        break;
      }
    }
  } else {
    log2("link %s was not present in sub-shard", linkName);
    child.Name = linkName;
    finalSegment.node.Links.push(child);
    finalSegment.children.set(index, true);
    log2("adding %s to existing sub-shard", linkName);
  }
  return updateShardedDirectory(path, blockstore, options);
};

// node_modules/@helia/unixfs/dist/src/commands/utils/cid-to-directory.js
async function cidToDirectory(cid, blockstore, options = {}) {
  const entry = await exporter(cid, blockstore, options);
  if (entry.type !== "directory") {
    throw new NotADirectoryError(`${cid.toString()} was not a UnixFS directory`);
  }
  return {
    cid,
    node: entry.node
  };
}

// node_modules/@helia/unixfs/dist/src/commands/utils/cid-to-pblink.js
async function cidToPBLink(cid, name, blockstore, options) {
  const sourceEntry = await exporter(cid, blockstore, options);
  if (sourceEntry.type !== "directory" && sourceEntry.type !== "file" && sourceEntry.type !== "raw") {
    throw new NotUnixFSError2(`${cid.toString()} was not a UnixFS node`);
  }
  return {
    Name: name,
    Tsize: sourceEntry.node instanceof Uint8Array ? sourceEntry.node.byteLength : dagNodeTsize(sourceEntry.node),
    Hash: cid
  };
}
function dagNodeTsize(node) {
  const linkSizes = node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), 0);
  return encode(node).byteLength + linkSizes;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/resolve.js
var log3 = logger("helia:unixfs:components:utils:resolve");
async function resolve7(cid, path, blockstore, options) {
  if (path == null || path === "") {
    return { cid };
  }
  const p = `/ipfs/${cid}${path == null ? "" : `/${path}`}`;
  const segments = await src_default2(walkPath(p, blockstore, options));
  if (segments.length === 0) {
    throw new DoesNotExistError("Could not find path in directory");
  }
  log3("resolved %s to %c", path, cid);
  return {
    cid: segments[segments.length - 1].cid,
    path,
    segments
  };
}
async function updatePathCids(cid, result, blockstore, options) {
  if (result.segments == null || result.segments.length === 0) {
    return cid;
  }
  let child = result.segments.pop();
  if (child == null) {
    throw new Error("Insufficient segments");
  }
  child.cid = cid;
  result.segments.reverse();
  for (const parent of result.segments) {
    const [directory, pblink] = await Promise.all([
      cidToDirectory(parent.cid, blockstore, options),
      cidToPBLink(child.cid, child.name, blockstore, options)
    ]);
    const result2 = await addLink(directory, pblink, blockstore, {
      ...options,
      allowOverwriting: true,
      cidVersion: cid.version
    });
    cid = result2.cid;
    parent.cid = cid;
    child = parent;
  }
  return cid;
}

// node_modules/@helia/unixfs/dist/src/commands/cat.js
var mergeOptions = merge_options_default.bind({ ignoreUndefined: true });
var defaultOptions = {};
async function* cat(cid, blockstore, options = {}) {
  const opts = mergeOptions(defaultOptions, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const result = await exporter(resolved.cid, blockstore, opts);
  if (result.type !== "file" && result.type !== "raw") {
    throw new NotAFileError();
  }
  if (result.content == null) {
    throw new NoContentError();
  }
  yield* result.content(opts);
}

// node_modules/@helia/unixfs/dist/src/commands/utils/constants.js
var SHARD_SPLIT_THRESHOLD_BYTES = 262144;

// node_modules/@helia/unixfs/dist/src/commands/chmod.js
var mergeOptions2 = merge_options_default.bind({ ignoreUndefined: true });
var log4 = logger("helia:unixfs:chmod");
var defaultOptions2 = {
  recursive: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function chmod(cid, mode, blockstore, options = {}) {
  const opts = mergeOptions2(defaultOptions2, options);
  const resolved = await resolve7(cid, opts.path, blockstore, options);
  log4("chmod %c %d", resolved.cid, mode);
  if (opts.recursive) {
    const root = await pipe(
      async function* () {
        for await (const entry of recursive(resolved.cid, blockstore, options)) {
          let metadata2;
          let links2 = [];
          if (entry.type === "raw") {
            metadata2 = new UnixFS({ type: "file", data: entry.node });
          } else if (entry.type === "file" || entry.type === "directory") {
            metadata2 = entry.unixfs;
            links2 = entry.node.Links;
          } else {
            throw new NotUnixFSError2();
          }
          metadata2.mode = mode;
          const node = {
            Data: metadata2.marshal(),
            Links: links2
          };
          yield {
            path: entry.path,
            content: node
          };
        }
      },
      // @ts-expect-error cannot combine progress types
      (source) => importer(source, blockstore, {
        ...opts,
        dagBuilder: async function* (source2, block2) {
          for await (const entry of source2) {
            yield async function() {
              const node = entry.content;
              const buf = encode(node);
              const updatedCid2 = await persist2(buf, block2, {
                ...opts,
                cidVersion: cid.version
              });
              if (node.Data == null) {
                throw new InvalidPBNodeError(`${updatedCid2} had no data`);
              }
              const unixfs2 = UnixFS.unmarshal(node.Data);
              return {
                cid: updatedCid2,
                size: BigInt(buf.length),
                path: entry.path,
                unixfs: unixfs2
              };
            };
          }
        }
      }),
      async (nodes) => src_default6(nodes)
    );
    if (root == null) {
      throw new UnknownError(`Could not chmod ${resolved.cid.toString()}`);
    }
    return updatePathCids(root.cid, resolved, blockstore, opts);
  }
  const block = await blockstore.get(resolved.cid, options);
  let metadata;
  let links = [];
  if (resolved.cid.code === code2) {
    metadata = new UnixFS({ type: "file", data: block });
  } else {
    const node = decode3(block);
    if (node.Data == null) {
      throw new InvalidPBNodeError(`${resolved.cid.toString()} had no data`);
    }
    links = node.Links;
    metadata = UnixFS.unmarshal(node.Data);
  }
  metadata.mode = mode;
  const updatedBlock = encode({
    Data: metadata.marshal(),
    Links: links
  });
  const hash = await sha256.digest(updatedBlock);
  const updatedCid = CID.create(resolved.cid.version, code3, hash);
  await blockstore.put(updatedCid, updatedBlock);
  return updatePathCids(updatedCid, resolved, blockstore, opts);
}

// node_modules/@helia/unixfs/dist/src/commands/cp.js
var mergeOptions3 = merge_options_default.bind({ ignoreUndefined: true });
var log5 = logger("helia:unixfs:cp");
var defaultOptions3 = {
  force: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function cp(source, target, name, blockstore, options = {}) {
  const opts = mergeOptions3(defaultOptions3, options);
  if (name.includes("/")) {
    throw new InvalidParametersError3("Name must not have slashes");
  }
  const [directory, pblink] = await Promise.all([
    cidToDirectory(target, blockstore, opts),
    cidToPBLink(source, name, blockstore, opts)
  ]);
  log5('Adding %c as "%s" to %c', source, name, target);
  const result = await addLink(directory, pblink, blockstore, {
    allowOverwriting: opts.force,
    cidVersion: target.version,
    ...opts
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/ls.js
var mergeOptions4 = merge_options_default.bind({ ignoreUndefined: true });
var defaultOptions4 = {};
async function* ls(cid, blockstore, options = {}) {
  const opts = mergeOptions4(defaultOptions4, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const result = await exporter(resolved.cid, blockstore);
  if (result.type === "file" || result.type === "raw") {
    yield result;
    return;
  }
  if (result.content == null) {
    throw new NoContentError();
  }
  if (result.type !== "directory") {
    throw new NotADirectoryError();
  }
  yield* result.content({
    offset: options.offset,
    length: options.length
  });
}

// node_modules/@helia/unixfs/dist/src/commands/mkdir.js
var mergeOptions5 = merge_options_default.bind({ ignoreUndefined: true });
var log6 = logger("helia:unixfs:mkdir");
var defaultOptions5 = {
  cidVersion: 1,
  force: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function mkdir(parentCid, dirname, blockstore, options = {}) {
  const opts = mergeOptions5(defaultOptions5, options);
  if (dirname.includes("/")) {
    throw new InvalidParametersError3("Path must not have slashes");
  }
  const entry = await exporter(parentCid, blockstore, options);
  if (entry.type !== "directory") {
    throw new NotADirectoryError(`${parentCid.toString()} was not a UnixFS directory`);
  }
  log6("creating %s", dirname);
  const metadata = new UnixFS({
    type: "directory",
    mode: opts.mode,
    mtime: opts.mtime
  });
  const node = {
    Data: metadata.marshal(),
    Links: []
  };
  const buf = encode(node);
  const hash = await sha256.digest(buf);
  const emptyDirCid = CID.create(opts.cidVersion, code3, hash);
  await blockstore.put(emptyDirCid, buf);
  const [directory, pblink] = await Promise.all([
    cidToDirectory(parentCid, blockstore, opts),
    cidToPBLink(emptyDirCid, dirname, blockstore, opts)
  ]);
  log6("adding empty dir called %s to %c", dirname, parentCid);
  const result = await addLink(directory, pblink, blockstore, {
    ...opts,
    allowOverwriting: opts.force
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/remove-link.js
var log7 = logger("helia:unixfs:utils:remove-link");
async function removeLink(parent, name, blockstore, options) {
  if (parent.node.Data == null) {
    throw new InvalidPBNodeError("Parent node had no data");
  }
  const meta = UnixFS.unmarshal(parent.node.Data);
  if (meta.type === "hamt-sharded-directory") {
    log7(`removing ${name} from sharded directory`);
    const result = await removeFromShardedDirectory(parent, name, blockstore, options);
    if (!await isOverShardThreshold(result.node, blockstore, options.shardSplitThresholdBytes, options)) {
      log7("converting shard to flat directory %c", parent.cid);
      return convertToFlatDirectory(result, blockstore, options);
    }
    return result;
  }
  log7(`removing link ${name} regular directory`);
  return removeFromDirectory(parent, name, blockstore, options);
}
var removeFromDirectory = async (parent, name, blockstore, options) => {
  parent.node.Links = parent.node.Links.filter((link) => {
    return link.Name !== name;
  });
  const parentBlock = encode(parent.node);
  const parentCid = await persist2(parentBlock, blockstore, {
    ...options,
    cidVersion: parent.cid.version
  });
  log7(`Updated regular directory ${parentCid}`);
  return {
    node: parent.node,
    cid: parentCid
  };
};
var removeFromShardedDirectory = async (parent, name, blockstore, options) => {
  const { path } = await recreateShardedDirectory(parent.cid, name, blockstore, options);
  const finalSegment = path[path.length - 1];
  if (finalSegment == null) {
    throw new Error("Invalid HAMT, could not generate path");
  }
  const linkName = finalSegment.node.Links.filter((l) => (l.Name ?? "").substring(2) === name).map((l) => l.Name).pop();
  if (linkName == null) {
    throw new Error("File not found");
  }
  const prefix = linkName.substring(0, 2);
  const index = parseInt(prefix, 16);
  finalSegment.node.Links = finalSegment.node.Links.filter((link) => link.Name !== linkName);
  finalSegment.children.unset(index);
  if (finalSegment.node.Links.length === 1) {
    while (true) {
      if (path.length === 1) {
        break;
      }
      const segment = path[path.length - 1];
      if (segment == null || segment.node.Links.length > 1) {
        break;
      }
      path.pop();
      const nextSegment = path[path.length - 1];
      if (nextSegment == null) {
        break;
      }
      const link = segment.node.Links[0];
      nextSegment.node.Links = nextSegment.node.Links.filter((l) => !(l.Name ?? "").startsWith(nextSegment.prefix));
      nextSegment.node.Links.push({
        Hash: link.Hash,
        Name: `${nextSegment.prefix}${(link.Name ?? "").substring(2)}`,
        Tsize: link.Tsize
      });
    }
  }
  return updateShardedDirectory(path, blockstore, options);
};
var convertToFlatDirectory = async (parent, blockstore, options) => {
  if (parent.node.Data == null) {
    throw new InvalidParametersError3("Invalid parent passed to convertToFlatDirectory");
  }
  const rootNode = {
    Links: []
  };
  const dir = await exporter(parent.cid, blockstore);
  if (dir.type !== "directory") {
    throw new Error("Unexpected node type");
  }
  for await (const entry of dir.content()) {
    let tsize = 0;
    if (entry.node instanceof Uint8Array) {
      tsize = entry.node.byteLength;
    } else {
      tsize = encode(entry.node).length;
    }
    rootNode.Links.push({
      Hash: entry.cid,
      Name: entry.name,
      Tsize: tsize
    });
  }
  const oldUnixfs = UnixFS.unmarshal(parent.node.Data);
  rootNode.Data = new UnixFS({ type: "directory", mode: oldUnixfs.mode, mtime: oldUnixfs.mtime }).marshal();
  const block = encode(prepare(rootNode));
  const cid = await persist2(block, blockstore, {
    codec: src_exports,
    cidVersion: parent.cid.version,
    signal: options.signal
  });
  return {
    cid,
    node: rootNode
  };
};

// node_modules/@helia/unixfs/dist/src/commands/rm.js
var mergeOptions6 = merge_options_default.bind({ ignoreUndefined: true });
var log8 = logger("helia:unixfs:rm");
var defaultOptions6 = {
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function rm(target, name, blockstore, options = {}) {
  const opts = mergeOptions6(defaultOptions6, options);
  if (name.includes("/")) {
    throw new InvalidParametersError3("Name must not have slashes");
  }
  const directory = await cidToDirectory(target, blockstore, opts);
  log8("Removing %s from %c", name, target);
  const result = await removeLink(directory, name, blockstore, {
    ...opts,
    cidVersion: target.version
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/stat.js
var mergeOptions7 = merge_options_default.bind({ ignoreUndefined: true });
var log9 = logger("helia:unixfs:stat");
var defaultOptions7 = {};
async function stat(cid, blockstore, options = {}) {
  var _a;
  const opts = mergeOptions7(defaultOptions7, options);
  const resolved = await resolve7(cid, options.path, blockstore, opts);
  log9("stat %c", resolved.cid);
  const result = await exporter(resolved.cid, blockstore, opts);
  if (result.type !== "file" && result.type !== "directory" && result.type !== "raw") {
    throw new NotUnixFSError2();
  }
  let fileSize = 0n;
  let dagSize = 0n;
  let localFileSize = 0n;
  let localDagSize = 0n;
  let blocks = 0;
  let mode;
  let mtime;
  const type = result.type;
  let unixfs2;
  if (result.type === "raw") {
    fileSize = BigInt(result.node.byteLength);
    dagSize = BigInt(result.node.byteLength);
    localFileSize = BigInt(result.node.byteLength);
    localDagSize = BigInt(result.node.byteLength);
    blocks = 1;
  }
  if (result.type === "directory") {
    fileSize = 0n;
    dagSize = BigInt(result.unixfs.marshal().byteLength);
    localFileSize = 0n;
    localDagSize = dagSize;
    blocks = 1;
    mode = result.unixfs.mode;
    mtime = result.unixfs.mtime;
    unixfs2 = result.unixfs;
  }
  if (result.type === "file") {
    const results = await inspectDag(resolved.cid, blockstore, opts);
    fileSize = result.unixfs.fileSize();
    dagSize = BigInt((((_a = result.node.Data) == null ? void 0 : _a.byteLength) ?? 0) + result.node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), 0));
    localFileSize = BigInt(results.localFileSize);
    localDagSize = BigInt(results.localDagSize);
    blocks = results.blocks;
    mode = result.unixfs.mode;
    mtime = result.unixfs.mtime;
    unixfs2 = result.unixfs;
  }
  return {
    cid: resolved.cid,
    mode,
    mtime,
    fileSize,
    dagSize,
    localFileSize,
    localDagSize,
    blocks,
    type,
    unixfs: unixfs2
  };
}
async function inspectDag(cid, blockstore, options) {
  const results = {
    localFileSize: 0,
    localDagSize: 0,
    blocks: 0
  };
  if (await blockstore.has(cid, options)) {
    const block = await blockstore.get(cid, options);
    results.blocks++;
    results.localDagSize += block.byteLength;
    if (cid.code === code2) {
      results.localFileSize += block.byteLength;
    } else if (cid.code === code3) {
      const pbNode = decode3(block);
      if (pbNode.Links.length > 0) {
        for (const link of pbNode.Links) {
          const linkResult = await inspectDag(link.Hash, blockstore, options);
          results.localFileSize += linkResult.localFileSize;
          results.localDagSize += linkResult.localDagSize;
          results.blocks += linkResult.blocks;
        }
      } else {
        if (pbNode.Data == null) {
          throw new InvalidPBNodeError(`PBNode ${cid.toString()} had no data`);
        }
        const unixfs2 = UnixFS.unmarshal(pbNode.Data);
        if (unixfs2.data == null) {
          throw new InvalidPBNodeError(`UnixFS node ${cid.toString()} had no data`);
        }
        results.localFileSize += unixfs2.data.byteLength ?? 0;
      }
    } else {
      throw new UnknownError(`${cid.toString()} was neither DAG_PB nor RAW`);
    }
  }
  return results;
}

// node_modules/@helia/unixfs/dist/src/commands/touch.js
var mergeOptions8 = merge_options_default.bind({ ignoreUndefined: true });
var log10 = logger("helia:unixfs:touch");
var defaultOptions8 = {
  recursive: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function touch(cid, blockstore, options = {}) {
  const opts = mergeOptions8(defaultOptions8, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const mtime = opts.mtime ?? {
    secs: BigInt(Math.round(Date.now() / 1e3)),
    nsecs: 0
  };
  log10("touch %c %o", resolved.cid, mtime);
  if (opts.recursive) {
    const root = await pipe(
      async function* () {
        for await (const entry of recursive(resolved.cid, blockstore)) {
          let metadata2;
          let links2;
          if (entry.type === "raw") {
            metadata2 = new UnixFS({ data: entry.node });
            links2 = [];
          } else if (entry.type === "file" || entry.type === "directory") {
            metadata2 = entry.unixfs;
            links2 = entry.node.Links;
          } else {
            throw new NotUnixFSError2();
          }
          metadata2.mtime = mtime;
          const node = {
            Data: metadata2.marshal(),
            Links: links2
          };
          yield {
            path: entry.path,
            content: node
          };
        }
      },
      // @ts-expect-error blockstore types are incompatible
      (source) => importer(source, blockstore, {
        ...opts,
        dagBuilder: async function* (source2, block2) {
          for await (const entry of source2) {
            yield async function() {
              const node = entry.content;
              const buf = encode(node);
              const updatedCid2 = await persist2(buf, block2, {
                ...opts,
                cidVersion: cid.version
              });
              if (node.Data == null) {
                throw new InvalidPBNodeError(`${updatedCid2} had no data`);
              }
              const unixfs2 = UnixFS.unmarshal(node.Data);
              return {
                cid: updatedCid2,
                size: BigInt(buf.length),
                path: entry.path,
                unixfs: unixfs2
              };
            };
          }
        }
      }),
      async (nodes) => src_default6(nodes)
    );
    if (root == null) {
      throw new UnknownError(`Could not chmod ${resolved.cid.toString()}`);
    }
    return updatePathCids(root.cid, resolved, blockstore, opts);
  }
  const block = await blockstore.get(resolved.cid, options);
  let metadata;
  let links = [];
  if (resolved.cid.code === code2) {
    metadata = new UnixFS({ data: block });
  } else {
    const node = decode3(block);
    links = node.Links;
    if (node.Data == null) {
      throw new InvalidPBNodeError(`${resolved.cid.toString()} had no data`);
    }
    metadata = UnixFS.unmarshal(node.Data);
  }
  metadata.mtime = mtime;
  const updatedBlock = encode({
    Data: metadata.marshal(),
    Links: links
  });
  const hash = await sha256.digest(updatedBlock);
  const updatedCid = CID.create(resolved.cid.version, code3, hash);
  await blockstore.put(updatedCid, updatedBlock);
  return updatePathCids(updatedCid, resolved, blockstore, opts);
}

// node_modules/@helia/unixfs/dist/src/unixfs.js
var UnixFS2 = class {
  constructor(components) {
    __publicField(this, "components");
    this.components = components;
  }
  async *addAll(source, options = {}) {
    yield* addAll(source, this.components.blockstore, options);
  }
  async addBytes(bytes, options = {}) {
    return addBytes(bytes, this.components.blockstore, options);
  }
  async addByteStream(bytes, options = {}) {
    return addByteStream(bytes, this.components.blockstore, options);
  }
  async addFile(file, options = {}) {
    return addFile(file, this.components.blockstore, options);
  }
  async addDirectory(dir = {}, options = {}) {
    return addDirectory(dir, this.components.blockstore, options);
  }
  async *cat(cid, options = {}) {
    yield* cat(cid, this.components.blockstore, options);
  }
  async chmod(cid, mode, options = {}) {
    return chmod(cid, mode, this.components.blockstore, options);
  }
  async cp(source, target, name, options = {}) {
    return cp(source, target, name, this.components.blockstore, options);
  }
  async *ls(cid, options = {}) {
    yield* ls(cid, this.components.blockstore, options);
  }
  async mkdir(cid, dirname, options = {}) {
    return mkdir(cid, dirname, this.components.blockstore, options);
  }
  async rm(cid, path, options = {}) {
    return rm(cid, path, this.components.blockstore, options);
  }
  async stat(cid, options = {}) {
    return stat(cid, this.components.blockstore, options);
  }
  async touch(cid, options = {}) {
    return touch(cid, this.components.blockstore, options);
  }
};

// node_modules/@helia/unixfs/dist/src/utils/glob-source.browser.js
async function* globSource() {
  throw new Error("Not supported in browsers");
}

// node_modules/@helia/unixfs/dist/src/utils/url-source.js
function urlSource(url, options) {
  return {
    path: decodeURIComponent(new URL(url).pathname.split("/").pop() ?? ""),
    content: readURLContent(url, options)
  };
}
async function* readURLContent(url, options) {
  const response = await globalThis.fetch(url, options);
  if (response.body == null) {
    throw new UnknownError("HTTP response did not have a body");
  }
  const reader = response.body.getReader();
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        return;
      }
      if (value != null) {
        yield value;
      }
    }
  } finally {
    reader.releaseLock();
  }
}

// node_modules/@helia/unixfs/dist/src/index.js
function unixfs(helia) {
  return new UnixFS2(helia);
}
export {
  globSource,
  unixfs,
  urlSource
};
//# sourceMappingURL=@helia_unixfs.js.map
